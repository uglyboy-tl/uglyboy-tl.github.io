<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>大模型专题分享 on 拾柒读库</title>
    <link>https://blog.uglyboy.cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98%E5%88%86%E4%BA%AB/</link>
    <description>Recent content in 大模型专题分享 on 拾柒读库</description>
    <generator>Hugo -- 0.143.1</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 08 Nov 2024 10:28:26 +0800</lastBuildDate>
    <atom:link href="https://blog.uglyboy.cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98%E5%88%86%E4%BA%AB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Agent 使用指南</title>
      <link>https://blog.uglyboy.cn/slides/2023/12/10/</link>
      <pubDate>Sun, 10 Dec 2023 09:55:03 +0800</pubDate>
      <guid>https://blog.uglyboy.cn/slides/2023/12/10/</guid>
      <description>&lt;div class=&#34;reveal&#34;&gt;
  &lt;div class=&#34;slides&#34;&gt;
    &lt;section data-markdown&gt;
      &lt;textarea data-template&gt;
      

## Agent 使用指南

---

### 如何在真实世界中使用大模型？

&amp;gt; 我说想开灯，大模型能帮我开灯吗？

---
- 我们希望大模型能够直接的解决问题
- 这样的使用方法现在被人们称为： **Agent**
---
#### 简单应用：如何修复一个 json 串？
-----
- 错误做法：
  - 问大模型这个字符串哪里错了？
  - 写代码修复字符串
- 正确做法：
  - &amp;#34;Do not change the specific content, fix the json, directly return the repaired JSON, without any explanation and dialogue.&amp;#34;

---
#### 什么情况下我们需要 Agent ？
-----
- 不需要的情况：
  - 操作简单，人可以快速解决；
  - 规则清晰，程序可以按规则解决；
- 需要的情况：
  - 解决步骤繁琐，对于人来说是重复劳动；
  - 情况复杂，不容易梳理清楚对应的解决规则；

---
#### 场景举例
-----
- Github 的 Copilot
- MacOS 的 Copilot
- 软件自动运维
- Yi 6B 的自动安装助手
- 上网助手
- $\dots$
---
#### 高级场景举例
-----
- 自动软件开发（GPT Engineer）
- 自动会议纪要
  - 自动任务记录
  - 自动会议预定
  - 自动消息通知
- 高级个人助理
- 一切自动化流程中需要人工参与的部分
---
#### 解决复杂问题有哪些难点？
-----
- 解决复杂问题往往需要很多步骤；
  - 而且正确的步骤往往也也需要探索；
- Agent 需要能够正确的了解自己当前解决问题的进度；
- 具体的步骤中，Agent 需要可以使用具体的工具；
---
#### 传统 Agent 的定义
###### **Agent = LLM &amp;#43; planning &amp;#43; memory &amp;#43; tools**
-----
&amp;lt;center&amp;gt;&amp;lt;img src=&amp;#34;https://s2.loli.net/2023/12/18/Pucaj8OELXfeTZm.jpg&amp;#34;&amp;gt;&amp;lt;/center&amp;gt;
---
### Agent 究竟是如何工作的？
---
#### ReAct：Agent 的核心模式
&amp;lt;center&amp;gt;&amp;lt;img src=&amp;#34;https://s2.loli.net/2023/12/18/klDFI9n2Mq5Kf61.png&amp;#34; width=&amp;#34;70%&amp;#34;&amp;gt;&amp;lt;/center&amp;gt;
---
#### ReAct 的核心思想
-----
- 循环试错（以此来取消幻觉）；
- 充分利用大模型的能力（复杂条件下也总能给出解决方案）；
  - 大模型的知识足够多，且有泛化性，适合解决复杂问题；
  - 大模型可以很好的理解复杂的条件，找出适合的解决方案；
- 通过对历史行为的记录（记忆），避免重复错误的尝试；
---
### Agent 测验
---

#### 如何打造一个联网的 LLM ？
-----
- **[Thought]** 针对用户输入，让 LLM 判断应该从哪个`搜索引擎`用什么`关键词` 获取结果；
- **[Act]** 获取`搜索引擎`在对应`关键词`下的搜索结果；
- **[Obs]** 具体返回的搜索结果；
- **[Thought]** 判断是否回答了用户的输入，如果没有，类似第一步，继续判断如何搜索；

---
#### 如何打造 Yi 6B 的自动安装助手
---
#### 如何打造 MacOS 的 Copilot
---
#### 如何打造一个可以自动软件开发的 Agent

---
### 这件事需要产品做什么？
---
- **找到适合的场景**
- 设计场景下的合理交互
- 总结场景下的最佳实践(作为数据喂给模型就可以了)
- 扩展场景
---
&amp;gt; 大模型还没有出现 Killer APP 是因为还没有懂 Agent 的产品经理
---

# Q &amp; A
      &lt;/textarea&gt;
    &lt;/section&gt;
  &lt;/div&gt;
&lt;/div&gt;</description>
      <content:encoded><![CDATA[<div class="reveal">
  <div class="slides">
    <section data-markdown>
      <textarea data-template>
      

## Agent 使用指南

---

### 如何在真实世界中使用大模型？

&gt; 我说想开灯，大模型能帮我开灯吗？

---
- 我们希望大模型能够直接的解决问题
- 这样的使用方法现在被人们称为： **Agent**
---
#### 简单应用：如何修复一个 json 串？
-----
- 错误做法：
  - 问大模型这个字符串哪里错了？
  - 写代码修复字符串
- 正确做法：
  - &#34;Do not change the specific content, fix the json, directly return the repaired JSON, without any explanation and dialogue.&#34;

---
#### 什么情况下我们需要 Agent ？
-----
- 不需要的情况：
  - 操作简单，人可以快速解决；
  - 规则清晰，程序可以按规则解决；
- 需要的情况：
  - 解决步骤繁琐，对于人来说是重复劳动；
  - 情况复杂，不容易梳理清楚对应的解决规则；

---
#### 场景举例
-----
- Github 的 Copilot
- MacOS 的 Copilot
- 软件自动运维
- Yi 6B 的自动安装助手
- 上网助手
- $\dots$
---
#### 高级场景举例
-----
- 自动软件开发（GPT Engineer）
- 自动会议纪要
  - 自动任务记录
  - 自动会议预定
  - 自动消息通知
- 高级个人助理
- 一切自动化流程中需要人工参与的部分
---
#### 解决复杂问题有哪些难点？
-----
- 解决复杂问题往往需要很多步骤；
  - 而且正确的步骤往往也也需要探索；
- Agent 需要能够正确的了解自己当前解决问题的进度；
- 具体的步骤中，Agent 需要可以使用具体的工具；
---
#### 传统 Agent 的定义
###### **Agent = LLM &#43; planning &#43; memory &#43; tools**
-----
&lt;center&gt;&lt;img src=&#34;https://s2.loli.net/2023/12/18/Pucaj8OELXfeTZm.jpg&#34;&gt;&lt;/center&gt;
---
### Agent 究竟是如何工作的？
---
#### ReAct：Agent 的核心模式
&lt;center&gt;&lt;img src=&#34;https://s2.loli.net/2023/12/18/klDFI9n2Mq5Kf61.png&#34; width=&#34;70%&#34;&gt;&lt;/center&gt;
---
#### ReAct 的核心思想
-----
- 循环试错（以此来取消幻觉）；
- 充分利用大模型的能力（复杂条件下也总能给出解决方案）；
  - 大模型的知识足够多，且有泛化性，适合解决复杂问题；
  - 大模型可以很好的理解复杂的条件，找出适合的解决方案；
- 通过对历史行为的记录（记忆），避免重复错误的尝试；
---
### Agent 测验
---

#### 如何打造一个联网的 LLM ？
-----
- **[Thought]** 针对用户输入，让 LLM 判断应该从哪个`搜索引擎`用什么`关键词` 获取结果；
- **[Act]** 获取`搜索引擎`在对应`关键词`下的搜索结果；
- **[Obs]** 具体返回的搜索结果；
- **[Thought]** 判断是否回答了用户的输入，如果没有，类似第一步，继续判断如何搜索；

---
#### 如何打造 Yi 6B 的自动安装助手
---
#### 如何打造 MacOS 的 Copilot
---
#### 如何打造一个可以自动软件开发的 Agent

---
### 这件事需要产品做什么？
---
- **找到适合的场景**
- 设计场景下的合理交互
- 总结场景下的最佳实践(作为数据喂给模型就可以了)
- 扩展场景
---
&gt; 大模型还没有出现 Killer APP 是因为还没有懂 Agent 的产品经理
---

# Q & A
      </textarea>
    </section>
  </div>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>RAG 技术</title>
      <link>https://blog.uglyboy.cn/slides/2023/11/23/</link>
      <pubDate>Thu, 23 Nov 2023 06:35:17 +0800</pubDate>
      <guid>https://blog.uglyboy.cn/slides/2023/11/23/</guid>
      <description>&lt;div class=&#34;reveal&#34;&gt;
  &lt;div class=&#34;slides&#34;&gt;
    &lt;section data-markdown&gt;
      &lt;textarea data-template&gt;
      

# RAG 技术

---

- 检索增强的生成系统（Retrieve Augment Generation）简称 RAG。
- 原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得与用户问题相关的更多上下文信息，使得的大语言模型可以：
  - 降低幻觉出现概率
  - 适应垂直场景应用
  - 弥补数据实时性不足

---

### 一个典型 RAG 系统的架构

&amp;lt;center&amp;gt;&amp;lt;img src=&amp;#34;https://oss.uglyboy.cn/image/2024/11/30e352cefa60c93ac742a0aee2d81cf7.jpg&amp;#34;&amp;gt;&amp;lt;/center&amp;gt;

---

### RAG 系统的核心技术要素

- 文档导入
- 文档切分
- 文档向量化
- 向量数据库选型
- 检索算法
- 文档排序
- Prompt 生成
- $\dots$
---

市面上大部分的关于 RAG 的介绍都是类似上面的逻辑进行的，然后就顺利的将 *某一种 RAG 的方法* 变成了 *通用 RAG 的框架*，从而让我们迷失了 RAG 的真正价值。

---

## 从定义出发，RAG 就是

## 检索 &amp;#43; 生成

---
- Chat With Documents 属于 RAG
- 用户对话中保留历史记忆 属于 RAG
- 网页搜索 &amp;#43; LLM 属于 RAG
- 自动调用 API 接口获取信息 属于 RAG
- 调用数据库获取信息 属于 RAG
- $\dots$
- **上面各种方法一起使用也属于 RAG**

---

## RAG 究竟意味着什么？

&amp;gt; 为什么我们要使用检索

---

- 人类行为的两种模式：主动获取信息（功利动机行为）和被动获取信息（共情动机行为）；
  - 通常在产品上，我们可以用 *Save time* 和 *Kill time* 的模式来区分
- 主动获取信息的手段被称为信息检索。
  - RAG 更标准的说法应当是有了 LLM 能力加持的信息检索。
---

## LLM 很难独立完成检索

---
- 最核心的问题是，对于如何引导大模型按照我们的意愿生成内容，**我们无法直接控制，我们只能通过增加上下文的方式来影响生成结果**。
  - 对于大模型来说，它会如何回答一个问题依赖的不是训练框架，而是训练数据。
  - 我们无法直接控制大模型的生成结果，但是我们可以通过增加上下文的方式来影响生成结果。
  - 一个问题，我们可以提供相关的上下文，然后利用大模型的泛化能力，让它生成我们想要的答案。

---

&amp;lt;center&amp;gt;&amp;lt;img src=&amp;#34;https://oss.uglyboy.cn/image/2024/11/4257471c0658350b4ddf3ec478c1a96c.png&amp;#34;&amp;gt;&amp;lt;/center&amp;gt;
---

- 大模型的“记忆力”并不可靠，不同的上下文会引导出怎样的结果是不确定的。
  - 仅靠大模型，是无法取消幻觉的。
- 如果 RAG 做得不好，可能带来的是负面效果。
---

## RAG 的核心
## 如何用好检索

---

## 检索的发展史

1. 图书馆的索引式检索（Yahoo 等目录网页）；
2. 关键词召回（传统搜索）；
3. 向量相似度（个性化推荐）；
4. 自然语言回答问题（大模型）；

&amp;gt; 这些方法不是递进的，而是并列的。

---

## 新概念下的 RAG 框架

---
1. 对用户问题分类，判断使用哪些检索器；
2. 根据用户问题，找到最适合的检索器检索方式（Query、SQL、API 调用等）；
3. 召回的结果，判断与用户问题的相关性，进行合理过滤或改进；
4. 用适合的方式组织召回结果，提供给 LLM 进行汇总并回答用户问题；
5. （可选）判断是否很好的回答了用户的问题，是否需要重新再来一遍（这其实就进化成 Agent 了）。

---
- 可以使用不同的 LLM 来执行不同的任务，这样就可以在计算速度和资源上得到极大的节约，并针对特定问题取得更好的效果。
- 检索器的各种优化技术都值得使用：
  - 包括传统的关键词搜索（QP）
  - 向量检索只是其中的一种手段；同时向量检索也应当额外建立适合的索引。
  - 知识图谱是有效的检索器之一。
  - 利用好结构化信息（数据库 或 API）。
- 好的检索器依赖好的数据。
---

# Q &amp; A

---

#### 如果我们有一些私有的数据，如何让大模型能够利用这些私有数据呢？

-----
- 通过微调的方式，将私有数据加入到大模型的训练数据中。
- 通过检索的方式，将私有数据加入到大模型的上下文中。
- **以上方法都用**

---

#### 怎样才能更好的提升 RAG 的效果？

-----

最核心的要素其实是：找到更优质的数据（准确、结构化）

---

#### 产品和开发要深入研究 Prompt Engineering 吗？

-----

永远都不要这样做，这件事交给 SFT

- 概念对比
- Let’s think step by step
- 通用优化 Prompt 的 Prompt
- function call
- Self RAG
- 让模型来学习如何 Prompt Engineering
      &lt;/textarea&gt;
    &lt;/section&gt;
  &lt;/div&gt;
&lt;/div&gt;</description>
      <content:encoded><![CDATA[<div class="reveal">
  <div class="slides">
    <section data-markdown>
      <textarea data-template>
      

# RAG 技术

---

- 检索增强的生成系统（Retrieve Augment Generation）简称 RAG。
- 原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得与用户问题相关的更多上下文信息，使得的大语言模型可以：
  - 降低幻觉出现概率
  - 适应垂直场景应用
  - 弥补数据实时性不足

---

### 一个典型 RAG 系统的架构

&lt;center&gt;&lt;img src=&#34;https://oss.uglyboy.cn/image/2024/11/30e352cefa60c93ac742a0aee2d81cf7.jpg&#34;&gt;&lt;/center&gt;

---

### RAG 系统的核心技术要素

- 文档导入
- 文档切分
- 文档向量化
- 向量数据库选型
- 检索算法
- 文档排序
- Prompt 生成
- $\dots$
---

市面上大部分的关于 RAG 的介绍都是类似上面的逻辑进行的，然后就顺利的将 *某一种 RAG 的方法* 变成了 *通用 RAG 的框架*，从而让我们迷失了 RAG 的真正价值。

---

## 从定义出发，RAG 就是

## 检索 &#43; 生成

---
- Chat With Documents 属于 RAG
- 用户对话中保留历史记忆 属于 RAG
- 网页搜索 &#43; LLM 属于 RAG
- 自动调用 API 接口获取信息 属于 RAG
- 调用数据库获取信息 属于 RAG
- $\dots$
- **上面各种方法一起使用也属于 RAG**

---

## RAG 究竟意味着什么？

&gt; 为什么我们要使用检索

---

- 人类行为的两种模式：主动获取信息（功利动机行为）和被动获取信息（共情动机行为）；
  - 通常在产品上，我们可以用 *Save time* 和 *Kill time* 的模式来区分
- 主动获取信息的手段被称为信息检索。
  - RAG 更标准的说法应当是有了 LLM 能力加持的信息检索。
---

## LLM 很难独立完成检索

---
- 最核心的问题是，对于如何引导大模型按照我们的意愿生成内容，**我们无法直接控制，我们只能通过增加上下文的方式来影响生成结果**。
  - 对于大模型来说，它会如何回答一个问题依赖的不是训练框架，而是训练数据。
  - 我们无法直接控制大模型的生成结果，但是我们可以通过增加上下文的方式来影响生成结果。
  - 一个问题，我们可以提供相关的上下文，然后利用大模型的泛化能力，让它生成我们想要的答案。

---

&lt;center&gt;&lt;img src=&#34;https://oss.uglyboy.cn/image/2024/11/4257471c0658350b4ddf3ec478c1a96c.png&#34;&gt;&lt;/center&gt;
---

- 大模型的“记忆力”并不可靠，不同的上下文会引导出怎样的结果是不确定的。
  - 仅靠大模型，是无法取消幻觉的。
- 如果 RAG 做得不好，可能带来的是负面效果。
---

## RAG 的核心
## 如何用好检索

---

## 检索的发展史

1. 图书馆的索引式检索（Yahoo 等目录网页）；
2. 关键词召回（传统搜索）；
3. 向量相似度（个性化推荐）；
4. 自然语言回答问题（大模型）；

&gt; 这些方法不是递进的，而是并列的。

---

## 新概念下的 RAG 框架

---
1. 对用户问题分类，判断使用哪些检索器；
2. 根据用户问题，找到最适合的检索器检索方式（Query、SQL、API 调用等）；
3. 召回的结果，判断与用户问题的相关性，进行合理过滤或改进；
4. 用适合的方式组织召回结果，提供给 LLM 进行汇总并回答用户问题；
5. （可选）判断是否很好的回答了用户的问题，是否需要重新再来一遍（这其实就进化成 Agent 了）。

---
- 可以使用不同的 LLM 来执行不同的任务，这样就可以在计算速度和资源上得到极大的节约，并针对特定问题取得更好的效果。
- 检索器的各种优化技术都值得使用：
  - 包括传统的关键词搜索（QP）
  - 向量检索只是其中的一种手段；同时向量检索也应当额外建立适合的索引。
  - 知识图谱是有效的检索器之一。
  - 利用好结构化信息（数据库 或 API）。
- 好的检索器依赖好的数据。
---

# Q & A

---

#### 如果我们有一些私有的数据，如何让大模型能够利用这些私有数据呢？

-----
- 通过微调的方式，将私有数据加入到大模型的训练数据中。
- 通过检索的方式，将私有数据加入到大模型的上下文中。
- **以上方法都用**

---

#### 怎样才能更好的提升 RAG 的效果？

-----

最核心的要素其实是：找到更优质的数据（准确、结构化）

---

#### 产品和开发要深入研究 Prompt Engineering 吗？

-----

永远都不要这样做，这件事交给 SFT

- 概念对比
- Let’s think step by step
- 通用优化 Prompt 的 Prompt
- function call
- Self RAG
- 让模型来学习如何 Prompt Engineering
      </textarea>
    </section>
  </div>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>大语言模型原理分享</title>
      <link>https://blog.uglyboy.cn/slides/2023/11/21/</link>
      <pubDate>Tue, 21 Nov 2023 01:45:37 +0800</pubDate>
      <guid>https://blog.uglyboy.cn/slides/2023/11/21/</guid>
      <description>&lt;div class=&#34;reveal&#34;&gt;
  &lt;div class=&#34;slides&#34;&gt;
    &lt;section data-markdown&gt;
      &lt;textarea data-template&gt;
      
# 大语言模型&amp;lt;br&amp;gt;原理分享
---

## 什么是大语言模型？
---

当我说了很多话之后，我马上要说 $\Box$

---

## 数学公式描述
-----
$w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是：

$$
p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i})
$$

---

## 大语言模型能做什么？

---

- 大模型能记住它看到过的一切信息。
- 大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。

---

### 大模型能达到怎样的泛化能力？

&amp;gt; 大模型可以涌现出智能吗？

---

## 大语言模型不能做什么？

---
1. 大模型无法判别一个 $\\\{[0|1]^*\\\}$ 序列中是否有奇数个 $1$。
2. 给定 $n$ 大模型无法生成 $(aa)^n$。
3. 大模型无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列。
4. 大模型无法执行加法运算。
5. $\dots$

---

大语言模型没有，也不可能具有推理能力。

&amp;gt; 大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。

---

## 大语言模型是如何将信息泛化的？

---

- 通过相似度计算来进行泛化，然后通过概率分布来进行选择。
    1. 粗略的可以如下理解：可以用同义词替代的都能被泛化。
    2. 这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。
    3. 在训练样本充分的情况下，可以跨语言进行同义词泛化。

---

# Q &amp; A
      &lt;/textarea&gt;
    &lt;/section&gt;
  &lt;/div&gt;
&lt;/div&gt;</description>
      <content:encoded><![CDATA[<div class="reveal">
  <div class="slides">
    <section data-markdown>
      <textarea data-template>
      
# 大语言模型&lt;br&gt;原理分享
---

## 什么是大语言模型？
---

当我说了很多话之后，我马上要说 $\Box$

---

## 数学公式描述
-----
$w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是：

$$
p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i})
$$

---

## 大语言模型能做什么？

---

- 大模型能记住它看到过的一切信息。
- 大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。

---

### 大模型能达到怎样的泛化能力？

&gt; 大模型可以涌现出智能吗？

---

## 大语言模型不能做什么？

---
1. 大模型无法判别一个 $\\\{[0|1]^*\\\}$ 序列中是否有奇数个 $1$。
2. 给定 $n$ 大模型无法生成 $(aa)^n$。
3. 大模型无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列。
4. 大模型无法执行加法运算。
5. $\dots$

---

大语言模型没有，也不可能具有推理能力。

&gt; 大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。

---

## 大语言模型是如何将信息泛化的？

---

- 通过相似度计算来进行泛化，然后通过概率分布来进行选择。
    1. 粗略的可以如下理解：可以用同义词替代的都能被泛化。
    2. 这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。
    3. 在训练样本充分的情况下，可以跨语言进行同义词泛化。

---

# Q & A
      </textarea>
    </section>
  </div>
</div>
]]></content:encoded>
    </item>
  </channel>
</rss>
