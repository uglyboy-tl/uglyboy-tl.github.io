<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>大模型专题分享 on 拾柒读库</title>
    <link>https://blog.uglyboy.cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98%E5%88%86%E4%BA%AB/</link>
    <description>Recent content in 大模型专题分享 on 拾柒读库</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 23 Nov 2023 06:35:17 +0800</lastBuildDate><atom:link href="https://blog.uglyboy.cn/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98%E5%88%86%E4%BA%AB/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG 技术</title>
      <link>https://blog.uglyboy.cn/slides/2.-rag%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Thu, 23 Nov 2023 06:35:17 +0800</pubDate>
      
      <guid>https://blog.uglyboy.cn/slides/2.-rag%E6%8A%80%E6%9C%AF/</guid>
      <description>RAG 技术 检索增强的生成系统（Retrieve Augment Generation）简称 RAG。 原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得</description>
      <content:encoded><![CDATA[<h1 id="rag-技术">RAG 技术</h1>
<hr>
<ul>
<li>检索增强的生成系统（Retrieve Augment Generation）简称 RAG。</li>
<li>原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得与用户问题相关的更多上下文信息，使得的大语言模型可以：
<ul>
<li>降低幻觉出现概率</li>
<li>适应垂直场景应用</li>
<li>弥补数据实时性不足</li>
</ul>
</li>
</ul>
<hr>
<h3 id="一个典型-rag-系统的架构">一个典型 RAG 系统的架构</h3>
<!-- raw HTML omitted -->
<hr>
<h3 id="rag-系统的核心技术要素">RAG 系统的核心技术要素</h3>
<ul>
<li>文档导入</li>
<li>文档切分</li>
<li>文档向量化</li>
<li>向量数据库选型</li>
<li>检索算法</li>
<li>文档排序</li>
<li>Prompt 生成</li>
<li>$\dots$</li>
</ul>
<hr>
<p>市面上大部分的关于 RAG 的介绍都是类似上面的逻辑进行的，然后就顺利的将 <code>某一种 RAG 的方法</code> 变成了 <code>通用 RAG 的框架</code>，从而让我们迷失了 RAG 的真正价值。</p>
<hr>
<h2 id="从定义出发rag-就是">从定义出发，RAG 就是</h2>
<h2 id="检索--生成">检索 + 生成</h2>
<hr>
<ul>
<li>Chat With Documents 属于 RAG</li>
<li>用户对话中保留历史记忆 属于 RAG</li>
<li>网页搜索 + LLM 属于 RAG</li>
<li>自动调用 API 接口获取信息 属于 RAG</li>
<li>调用数据库获取信息 属于 RAG</li>
<li>$\dots$</li>
<li><strong>上面各种方法一起使用也属于 RAG</strong></li>
</ul>
<hr>
<h2 id="rag-究竟意味着什么">RAG 究竟意味着什么？</h2>
<blockquote>
<p>为什么我们要使用检索</p>
</blockquote>
<hr>
<ul>
<li>人类行为的两种模式：主动获取信息（功利动机行为）和被动获取信息（共情动机行为）；
<ul>
<li>通常在产品上，我们可以用 <code>Save time</code> 和 <code>Kill time</code> 的模式来区分</li>
</ul>
</li>
<li>主动获取信息的手段被称为信息检索。
<ul>
<li>RAG 更标准的说法应当是有了 LLM 能力加持的信息检索。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="llm-很难独立完成检索">LLM 很难独立完成检索</h2>
<hr>
<ul>
<li>最核心的问题是，对于如何引导大模型按照我们的意愿生成内容，<strong>我们无法直接控制，我们只能通过增加上下文的方式来影响生成结果</strong>。
<ul>
<li>对于大模型来说，它会如何回答一个问题依赖的不是训练框架，而是训练数据。</li>
<li>我们无法直接控制大模型的生成结果，但是我们可以通过增加上下文的方式来影响生成结果。</li>
<li>一个问题，我们可以提供相关的上下文，然后利用大模型的泛化能力，让它生成我们想要的答案。</li>
</ul>
</li>
</ul>
<hr>
<!-- raw HTML omitted -->
<ul>
<li>大模型的“记忆力”并不可靠，不同的上下文会引导出怎样的结果是不确定的。
<ul>
<li>仅靠大模型，是无法取消幻觉的。</li>
</ul>
</li>
<li>如果 RAG 做得不好，可能带来的是负面效果。</li>
</ul>
<hr>
<h2 id="rag-的核心">RAG 的核心</h2>
<h2 id="如何用好检索">如何用好检索</h2>
<hr>
<h2 id="检索的发展史">检索的发展史</h2>
<ol>
<li>图书馆的索引式检索（Yahoo 等目录网页）；</li>
<li>关键词召回（传统搜索）；</li>
<li>向量相似度（个性化推荐）；</li>
<li>自然语言回答问题（大模型）；</li>
</ol>
<blockquote>
<p>这些方法不是递进的，而是并列的。</p>
</blockquote>
<hr>
<h2 id="新概念下的-rag-框架">新概念下的 RAG 框架</h2>
<hr>
<ol>
<li>对用户问题分类，判断使用哪些检索器；</li>
<li>根据用户问题，找到最适合的检索器检索方式（Query、SQL、API 调用等）；</li>
<li>召回的结果，判断与用户问题的相关性，进行合理过滤或改进；</li>
<li>用适合的方式组织召回结果，提供给 LLM 进行汇总并回答用户问题；</li>
<li>（可选）判断是否很好的回答了用户的问题，是否需要重新再来一遍（这其实就进化成 Agent 了）。</li>
</ol>
<hr>
<ul>
<li>可以使用不同的 LLM 来执行不同的任务，这样就可以在计算速度和资源上得到极大的节约，并针对特定问题取得更好的效果。</li>
<li>检索器的各种优化技术都值得使用：
<ul>
<li>包括传统的关键词搜索（QP）</li>
<li>向量检索只是其中的一种手段；同时向量检索也应当额外建立适合的索引。</li>
<li>知识图谱是有效的检索器之一。</li>
<li>利用好结构化信息（数据库 或 API）。</li>
</ul>
</li>
<li>好的检索器依赖好的数据。</li>
</ul>
<hr>
<h1 id="q--a">Q &amp; A</h1>
<hr>
<h4 id="如果我们有一些私有的数据如何让大模型能够利用这些私有数据呢">如果我们有一些私有的数据，如何让大模型能够利用这些私有数据呢？</h4>
<hr>
<ul>
<li>通过微调的方式，将私有数据加入到大模型的训练数据中。</li>
<li>通过检索的方式，将私有数据加入到大模型的上下文中。</li>
<li><strong>以上方法都用</strong></li>
</ul>
<hr>
<h4 id="怎样才能更好的提升-rag-的效果">怎样才能更好的提升 RAG 的效果？</h4>
<hr>
<p>最核心的要素其实是：找到更优质的数据（准确、结构化）</p>
<hr>
<h4 id="产品和开发要深入研究-prompt-engineering-吗">产品和开发要深入研究 Prompt Engineering 吗？</h4>
<hr>
<p>永远都不要这样做，这件事交给 SFT</p>
<ul>
<li>概念对比</li>
<li>Let’s think step by step</li>
<li>通用优化 Prompt 的 Prompt</li>
<li>function call</li>
<li>Self RAG</li>
<li>让模型来学习如何 Prompt Engineering</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>大语言模型原理分享</title>
      <link>https://blog.uglyboy.cn/slides/1.-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%88%86%E4%BA%AB/</link>
      <pubDate>Tue, 21 Nov 2023 01:45:37 +0800</pubDate>
      
      <guid>https://blog.uglyboy.cn/slides/1.-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%88%86%E4%BA%AB/</guid>
      <description>大语言模型原理分享 什么是大语言模型？ 当我说了很多话之后，我马上要说 $\Box$ 数学公式描述 $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ 大语言模型</description>
      <content:encoded><![CDATA[<h1 id="大语言模型br原理分享">大语言模型<!-- raw HTML omitted -->原理分享</h1>
<hr>
<h2 id="什么是大语言模型">什么是大语言模型？</h2>
<hr>
<p>当我说了很多话之后，我马上要说 $\Box$</p>
<hr>
<h2 id="数学公式描述">数学公式描述</h2>
<hr>
<p>$w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是：</p>
<p>$$
p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i})
$$</p>
<hr>
<h2 id="大语言模型能做什么">大语言模型能做什么？</h2>
<hr>
<ul>
<li>大模型能记住它看到过的一切信息。</li>
<li>大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。</li>
</ul>
<hr>
<h3 id="大模型能达到怎样的泛化能力">大模型能达到怎样的泛化能力？</h3>
<blockquote>
<p>大模型可以涌现出智能吗？</p>
</blockquote>
<hr>
<h2 id="大语言模型不能做什么">大语言模型不能做什么？</h2>
<hr>
<ol>
<li>大模型无法判别一个 $\{[0|1]^*\}$ 序列中是否有奇数个 $1$。</li>
<li>给定 $n$ 大模型无法生成 $(aa)^n$。</li>
<li>大模型无法判定 $\{0^n\#1^n\}$ 形式的序列。</li>
<li>大模型无法执行加法运算。</li>
<li>$\dots$</li>
</ol>
<hr>
<p>大语言模型没有，也不可能具有推理能力。</p>
<blockquote>
<p>大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。</p>
</blockquote>
<hr>
<h2 id="大语言模型是如何将信息泛化的">大语言模型是如何将信息泛化的？</h2>
<hr>
<ul>
<li>通过相似度计算来进行泛化，然后通过概率分布来进行选择。
<ol>
<li>粗略的可以如下理解：可以用同义词替代的都能被泛化。</li>
<li>这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。</li>
<li>在训练样本充分的情况下，可以跨语言进行同义词泛化。</li>
</ol>
</li>
</ul>
<hr>
<h1 id="q--a">Q &amp; A</h1>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
