<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>编码 on 拾柒读库</title>
    <link>https://blog.uglyboy.cn/tags/%E7%BC%96%E7%A0%81/</link>
    <description>Recent content in 编码 on 拾柒读库</description>
    <generator>Hugo -- 0.139.3</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 13 Nov 2024 22:28:11 +0800</lastBuildDate>
    <atom:link href="https://blog.uglyboy.cn/tags/%E7%BC%96%E7%A0%81/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>大模型的推理能力</title>
      <link>https://blog.uglyboy.cn/posts/2024/11/06/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Wed, 06 Nov 2024 18:44:15 +0800</pubDate>
      <guid>https://blog.uglyboy.cn/posts/2024/11/06/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B/</guid>
      <description>对推理能力的一个科学描述</description>
      <content:encoded><![CDATA[<h2 id="引言">引言</h2>
<p>自 GPT3.5 引爆大模型概念以来，大家都期盼着 AGI<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 的到来。但与此同时，当下各类大模型虽然依据 Scaling Law<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>，不断提升各方面的性能，但是关于模型的推理能力，总显得不足。</p>
<p>甚至科研界针对大模型究竟是否可能具有推理能力，也争论不休。例如下列近期比较热烈的讨论：</p>
<ul>
<li>DeepMind 的 <a href="https://arxiv.org/html/2402.04494v1">Grandmaster-Level Chess Without Search</a></li>
<li>Apple 的 <a href="https://arxiv.org/abs/2410.05229">GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models</a></li>
<li>MIT 的 <a href="https://www.nature.com/articles/s41586-024-07522-w">Language is primarily a tool for communication rather than thought</a></li>
<li>Google Brain 的 <a href="https://arxiv.org/abs/2402.12875">Chain of Thought Empowers Transformers to Solve Inherently Serial Problems</a></li>
<li><a href="https://www.strangeloopcanon.com/p/what-can-llms-never-do">What can LLMs never do?</a></li>
</ul>
<p>虽然笔者之前的文章已经用比较直观的方式证明了 LLM 的基本范式 <code>N-GRAM</code> 是一个有穷自动机，无法像通用图灵机一样完成各种任务，甚至简单的四则运算也做不到，从而侧面证明了 LLM 不可能具有推理能力。但是“究竟什么是推理能力？”这个话题，之前并没有进行过完整的阐述。</p>
<p>本文将对什么是推理能力这个话题进行深入的说明，进而将 LLM 未来如何能实现 AGI 的路线图进行一个完整而具体的展现。</p>
<h2 id="推理逻辑算法图灵机">推理、逻辑、算法、图灵机</h2>
<h3 id="推理和数理逻辑">推理和数理逻辑</h3>
<p>研究推理能力，那首先需要有一个“推理”的明确的说明或定义。推理这个概念来自于逻辑学，古早的逻辑学更偏向于哲学，但现代的逻辑学已经是数理逻辑的一部分了。</p>
<p><strong>数理逻辑</strong>（Mathematical logic）是用数学方法研究诸如推理的有效性、证明的真实性、数学的真理性和计算的可行性等这类现象中的逻辑问题的一门学问。现在公认的数理逻辑创始人是莱布尼兹。他的目的是选出一种“通用代数”，其中把一切推理都化归为计算。</p>
<blockquote>
<p>更为具体的解释：我们希望研究的是“正确的推理过程”，而数理逻辑的目标是将推理过程变成一种计算过程（算法），进而通过计算的结果来判断推理的正确性。</p>
</blockquote>
<p>这个愿望被布尔代数<strong>基本</strong>实现了——我们可以将任何数学语句或自然语言的命题翻译为为布尔代数的逻辑表达式，然后对表达式进行判定是否为真。当然，这个实现是不完美的，罗素在数理逻辑中发现了悖论；而哥德尔证明了悖论是一切逻辑体系中必然存在的命题——也就是说，一定存在我们无法判定是否为真的逻辑表达式。</p>
<h3 id="计算和图灵机">计算和图灵机</h3>
<p>有了数理逻辑这种工具，推理能力被转化为了计算能力。可计算能力又如何衡量呢？在另一条时间线上，一个叫图灵的“年轻人”在研究“算法”的能力，而这条线恰好将计算能力的清晰的描述了出来。</p>
<p>图灵提出了一种通用图灵机，并证明了当前人类能想象到的一切算法，都可以用通用图灵机实现。</p>
<blockquote>
<p>当然，他的副产物：有穷自动机、上下文无关文法等算法模式，能力是弱于图灵机的。这也是笔者用于证明当前的 LLM 不具有推理能力的重要工具。</p>
</blockquote>
<p>于此同时，图灵还深入研究了图灵机进行计算的可判定性，也就是停机定理：存在这样的图灵机，我们无法判断它是否陷入了无限循环，能否停机。</p>
<p>非常有趣的是，停机定理的证明和歌德尔不完备定理的证明思路很类似，都是将一切命题（算法）转化为一串数字，然后再证明这其中的不合理性。</p>
<blockquote>
<p>甚至，我们可以直接通过停机定理来证明歌德尔不完备定理：
我们将数理逻辑体系下的逻辑命题转化为一个计算问题，然后通过算法对这个问题计算。于是逻辑命题能否判定就变成了判断这个算法的结果或者判定这个算法无法停机（也就是这是个逻辑悖论）。
但由于停机定理的存在，我们并不能对一切逻辑命题给出上面的判定，从而，一定有逻辑命题是我们无法给出任何判定的。</p>
</blockquote>
<h3 id="计算机和可编译">计算机和可编译</h3>
<p>上面的论述是理论层面的描述，我们需要一个针对真实“推理”问题的可操作的工具。幸好还有一个人，跟图灵所处同一时代，用另一种方式真实实现了“通用图灵机”，并且它还成为了人类进步的重要工具：计算机之父——冯·诺依曼。</p>
<p>我们今天的手机、电脑等等各种电子产品，基本都是冯·诺依曼架构下实现的。而今天的程序员，则不断将图灵理论中的概念算法，转换成真实世界中不断运行中的程序。</p>
<p>而这其中，刨除停机定理中描述的无法判定的算法问题，绝大部分算法能否执行的重要判定标准是：<strong>可编译</strong> <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>。</p>
<p>从而最终，我们有了关于推理的全部知识：<strong>一个正确的推理，是将其所有逻辑过程通过数理逻辑相容的编码进行描述，然后看该编码能否通过其对应的编译器的编译</strong>。</p>
<ul>
<li>Lean4 就是一门进行数学推理的可编译代码。</li>
<li><a href="https://arxiv.org/abs/2405.18357">Faithful Logical Reasoning via Symbolic Chain-of-Thought</a> 这篇文章介绍了一些外部推理工具如何帮助大模型进行无谬误的推理，并提出了一个新的推理编码（符号逻辑推理）。</li>
</ul>
<h2 id="提升推理能力">提升推理能力</h2>
<p>上一节中，我们有了清晰的定义，知道了什么叫做“推理”以及“可验证的正确推理”。那么什么是推理能力呢？</p>
<h3 id="推理过程的数学描述">推理过程的数学描述</h3>
<p>针对真实世界的推理问题，其基本范式都符合如下的描述：</p>
<ol>
<li>我们有一些已知条件或者背景信息（知识）；</li>
<li>我们有一个预期的结果：
<ul>
<li>可能是类似数学证明题，我们有一个命题，希望知道其是否正确；</li>
<li>可能是类似规划问题，虽然我们不知道最终的答案，但我们可以验证怎样的答案符合我们的预期；</li>
<li>也可能是类似计算机竞赛的算法问题，我们不仅仅要求答案符合预期，还期望计算的过程更快，使用更少的资源等等；</li>
</ul>
</li>
<li>我们的推理过程其实可以看作是一个检索过程——在已知信息和目标结果之间寻找并补充适合的逻辑代码，让其可通过我们所需要的推理编译器。</li>
</ol>
<h3 id="推理能力">推理能力</h3>
<p>当前大模型欠缺的，正是上面描述的推理过程的能力 <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>。</p>
<p>笔者以前文章中给出过结论：通过强化学习的 Agent 模式可以实现通用图灵机，进而实现 AGI。今天用新的关于推理的数学定义，再次推演出这个结论：</p>
<blockquote>
<p>强化学习（Reinforcement learning，RL）讨论的问题是一个<strong>智能体 (agent)</strong> 怎么在一个复杂不确定的 <strong>环境 (environment)</strong> 里面去极大化它能获得的奖励。通过感知所处环境的 <strong>状态 (state)</strong> 对 <strong>动作 (action)</strong> 的 <strong>反应 (reward)</strong>， 来指导更好的动作，从而获得最大的 <strong>收益 (return)</strong>，这被称为在交互中学习，这样的学习方法就被称作强化学习。
它的一个巨大优势，就是可以将多步之后的奖励，拆解反馈到很多步以前的状态中，从而可以更快的学习到重要的经验。
这一点和我们进行推理过程时所需要的能力是完全一致的：因为我们的推理过程的最终结果是可验证（可编译）的，通过时可以给予一个巨大的奖励。而强化学习的过程就是不断通过后验的奖励，让系统在下一次时更快更好的找到适合的推理过程。</p>
</blockquote>
<p>甚至可以给出结论：推理能力提升的过程，就是一个标准的强化学习过程 <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>。</p>
<h2 id="技术瓶颈">技术瓶颈</h2>
<p>从过去一年里 LLM 的发展来看，推理能力的进展无疑是缓慢的。甚至应该也有其他的研究者摸到了所谓“推理为何物”的基本认知，但依然在解决这个课题的方面，没看到什么显著突破。</p>
<p>核心的技术瓶颈，在于两个方面：</p>
<ol>
<li>对推理过程的符号化描述 <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>；</li>
<li>强化学习中对非确定型状态空间 <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> 的描述和建模。</li>
</ol>
<h3 id="推理的符号化描述">推理的符号化描述</h3>
<p>如果是从数学角度来看，推理的符号化描述的工具已经是完备的了。但从真实应用出发，却没那么容易将我们人类知识中的大量推理过程进行符号化表达。</p>
<p>这里的最核心的难点，不在于符号体系本身，而是人类有大量蕴含推理知识的表达，还没有用符号体系进行描述，于是很多人类的推理过程在转译成符号化描述时，是不完备甚至缺失的。</p>
<blockquote>
<p>这一点在 Lean4 语言中非常明显。理论上，Lean4 是完备的，可以进行各种数学推理。但是真正用起来的时候，却会发现基本没法用——因为人类的大量证明过程中，会用到很多理所应当的定理，比如理所应当的加法交换率，分配率，可被整除等等。但这些概念在数学中其实并不是公理，也不是基础概念，是需要从集合论一直证明到自然数是一个阿贝尔环，才能使用的逻辑前提。
所以 Lean4 中缺失的不是逻辑，而是很多基础推导过程的证明。而这种问题存在于所有的逻辑符号化编码中。</p>
</blockquote>
<p>人类的知识蕴含在语言中，而语言的进化又蕴含了非常多的逻辑知识。在这些基本的知识没有被全面的符号化描述前，任何符号化描述的推导过程都是不完备的。</p>
<p>而另一方面，我们无论是尝试用 LLM 来学习这种 符号化描述的表达，还是用强化学习，都需要大量的数据作为食材。而更不幸的时，我们连推理的符号化描述体系都还没统一和建立起来，更不用提所需要的大量学习样本了。</p>
<p>所以短期内快速的提升人工智能的推理能力，从数据和表达的层面来看，都是基本不可能的。</p>
<h3 id="强化学习方面的瓶颈">强化学习方面的瓶颈</h3>
<p>强化学习方面，我们的工具库也是不足的。</p>
<p>例如针对下面的命题，我们是有能力构建完善的符号化描述和样本库的：</p>
<ul>
<li>自然数（实数）加法的运算规则。</li>
</ul>
<p>我们希望用强化学习的方式，从足够多的样本中学习出加法的运算规则。但面对这个命题时，就会发现，如何在强化学习中表达这种非确定型的命题的状态空间和动作空间是一个巨大的难题。</p>
<p>如果单说解决这个问题，给出一些例如操作存储、按位移动等操作类型，或许也可以表达动作空间和状态空间，但是这种方式基本上是对着答案设计动作空间。针对更广泛的各种符号化描述的真实问题，如何描述状态空间和动作空间，并能进行有效的计算？是一个实打实的难题。</p>
<p>甚至相比于强化学习模型，LLM 模型可以在更长的序列中进行 token 的概率预测，甚至状态空间和动作空间都是 token 表达的泛化类型，这也使得 LLM 在统计已有的数据的奖励权重方面，其泛化性和易用性都是强于当下的强化学习模型的。</p>
<p>那有没有办法让强化学习也可以利用长序列编码的方式表达状态和动作空间，并用类似于 LLM 模型的方式来计算激励函数呢？看起来是个可行的路线，但似乎依然需要先有更适合的关于状态空间的符号化表达，以及全新的一套强化学习机制，来更通用的适应各种不同的非确定型的真实问题。</p>
<h2 id="结论">结论</h2>
<p>短期内 AGI 不可实现。而 LLM 的能力基本已到瓶颈，一段时间内大家的竞争将更聚焦在应用层面。</p>
<p>如果想尝试探索提升 LLM 的推理能力，那最重要的两个方向：</p>
<ol>
<li>推理的符号化表达，以及构建更多的符号化表达的数据（这里或许可以用 LLM 来帮忙生成或转译）；</li>
<li>更强大的强化学习范式。</li>
</ol>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>通用人工智能&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>大模型的尺度规则：随着参数规模的扩大，模型能力更强&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>甚至如果将回归测试也看作是编译的规则，那么对算法进行一定程度的准确性判断也可以通过编译的方式来实现。&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>甚至“能力”一词表达的，都不是推理过程的效率高低，而是推理过程能成功的概率。&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>这也是现在包括 o1 在内的各种推理模型背后的核心原理。当然，经验不沉淀在强化学习模型中，而是沉淀在基座模型中，无疑会损失很多推理的能力。&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>其实叫做编码也可以，但容易跟传统的编码概念混淆，毕竟推理所要求的编码是可编译的；而 LLM 要求的编码只要有可预测性即可。&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>这种表述也许有更专业的表达。笔者想说的是，强化学习中动作空间当下是未知的，只有动作出现后，我们才会知道原来还有这样的动作；但是理论上最终的动作空间总是有办法可以被全部表达出来的，也许表达的方式是某个动作编码的判别器。所以这里或许需要有新的对动作空间的数学描述方式，才有可能用传统的强化学习的方式来枚举所有的动作空间。&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
    <item>
      <title>编码的意义</title>
      <link>https://blog.uglyboy.cn/posts/2024/09/18/%E7%BC%96%E7%A0%81%E7%9A%84%E6%84%8F%E4%B9%89/</link>
      <pubDate>Wed, 18 Sep 2024 10:38:40 +0800</pubDate>
      <guid>https://blog.uglyboy.cn/posts/2024/09/18/%E7%BC%96%E7%A0%81%E7%9A%84%E6%84%8F%E4%B9%89/</guid>
      <description>大模型发挥能力被忽视的要素</description>
      <content:encoded><![CDATA[<h2 id="导言">导言</h2>
<p>伴随着大模型研究的推进和在应用中的实践，我们发现了一个现象——对于现有的 LLM 模型而言，一个好的编码可能会对其模型能力带来极大的助力。</p>
<p>关于这方面的思考其实由来已久，早前在听闻“压缩即智能”的论断，以及相关的数学阐述时，就产生过一种奇妙的念头：</p>
<ul>
<li>如果我们对我们正常的语言进行编码压缩，这样得到的文本信息的压缩率会更高，对压缩过的文本再进行 LLM 的训练，会发生什么？</li>
<li>LLM 生成的编码还能被正常的解压缩成文本吗？解压缩之后的文本还能流畅通顺吗？</li>
<li>这样训练出的 LLM 会不会压缩率更高？那它会更加智能吗？</li>
</ul>
<p>后来，在搞清楚了“压缩即智能” 那篇演讲，背后所提到的<strong>压缩</strong> 概念，不过是<strong>算术编码</strong>的基础运用后，这种思考便放下了 <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>。</p>
<p>现在重新聊回编码问题，从编码的角度来看看 LLM 的本质。</p>
<h2 id="信息和熵">信息和熵</h2>
<p>回归到 LLM 的模型范式，过去的研究主要都将重点集中在了 Transformer 和深度学习的神奇泛化能力方面，通过更大规模的训练（Scaling Law），降低泛化误差。但究其本质，训练的逼近只是一个数值优化（压缩映射）的过程，优化的目标才是这件事起到作用的关键。</p>
<h3 id="llm-更应该叫大编码模型"><strong>LLM</strong> 更应该叫大编码模型</h3>
<p>LLM 是信息预测模型：利用时序上已知的信息，对下一个时刻出现的信息进行预测。</p>
<p>但信息本身是需要被表征出来，才能进行读取（理解）和预测，而信息的表征方式就是<strong>编码</strong>。</p>
<blockquote>
<p>多模态的大模型相比于文本大模型本质上没有任何不同之处，仅仅是表达信息的编码不同，认为多模态比基于文本的大模型拥有更丰富的信息这一点是存疑的。但这一点还不是多模态大模型最大的问题。</p>
<p>另一个十分重要的因素，就是多模态的编码相比于语言这种编码，在进行预测时很可能天然就有十分巨大的劣势。这一点将在后文中引入了信息度量：“熵”之后，进行更深入的讨论。</p>
</blockquote>
<p>大模型的内核，正是基于已有的编码的信息，预测新的编码。预测的具体内容，是新编码出现的概率。</p>
<p>这里会有一个思考，不同的编码方式，是否会对预测本身的质量产生影响呢？</p>
<blockquote>
<p>从实践的角度来看，是有很大影响的。所以大语言模型都会有自已的 embedding 算法，而不是直接使用字母表或者 unicode 编码进行分析。</p>
<p>但我们如何从理论的解读来理解和分析这个结果呢？我们很需要引入一个能更好的描述编码相关特性的物理量。</p>
</blockquote>
<p>而在数学中刻画信息、编码、概率的模型是香农的信息论。其中最深刻的刻画就是信息熵。</p>
<h3 id="熵">熵</h3>
<p>熵的概念，本质上是一个系统里单位时间内的信息密度，或者说，是我们对未来时刻进行预测的难度。</p>
<p>所以自然的，一个时刻出现的概率非常的低，那么这一刻我们对未来的预测就会非常的难；同时因为熵是个可描述的物理量（具有可加性），自然就会引出其常见的定义方式：</p>
<p>$$
H = - \sum p \ln p
$$</p>
<p>在这个意义下，Boltzmann 熵、Gibbs 熵 和 香农的信息熵是一致的。于是很容易引入一个十分热门的概念：<strong>热力学第二定律</strong>。</p>
<h4 id="热力学第二定律">热力学第二定律</h4>
<blockquote>
<p>[!tip] 热力学第二定律</p>
<p>在不受任何外部影响的条件下，一个系统的熵会不断增加。更具体的说，就是系统中的每个个体都会走向更加随机（概率更小），导致整个系统的可预测性越来越低。</p>
</blockquote>
<p>需要注意的是，热力学第二定律并不是一个完美的时序判别器，它是一个概率性的时间方向指引：</p>
<ul>
<li>也就是说可能会存在很多个瞬间，系统的熵减少了；</li>
<li>甚至一定存在某个很极端的概率事件——系统的熵一直在减少；</li>
</ul>
<p>但这些都是概率空间上的正常表现，宏观视角来看，熵的增加是稳定的。</p>
<p>在这种情况下，我们很容易发现，信息几乎是不可预测——随着信息中的要素的增加，想要预测下一时刻的信息所需要的信息量会按照热力学第二定律，不断增加，直至不可计算 <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。</p>
<blockquote>
<p>为了更好的理解熵和不可计算，我们以三体问题为例。</p>
<p>我们要想预测三体未来一小段时间的运动轨迹，所需要的信息是在这一时刻前更长一段时间的历史三体运动信息，获得的历史运动信息越多越精准，对未来的预测就能越精准，预测正确的时间就会更长一些。但永远没办法做到像计算行星轨道一样，给出公式性的结果，这种情况就属于不可计算。</p>
<p>从三体出发，如果想预测四体，需要比三体更加庞大的数据量才足以支撑相同时间长短的预测。随着 $n$ 体中 $n$ 的不断增长，我们能够有效的预测的时间就会越来越小。</p>
<p>这种现象背后的数学基础是动力系统中的混沌现象，本文不对这个问题进行更深入的解读，对此有兴趣可以参考我的《系统理论》进行理解。</p>
</blockquote>
<h3 id="编码">编码</h3>
<p>编码不是物理学自然的结果，编码是随着生物的出现而出现的。更聚焦的说，编码是生物体对于一些固定特征合集的概括。尤其是，编码的出现，其实意味着某些固定特征合集的重复出现（高概率）。而从信息论出发，对于高概率的事件，通过编码（更短的信号）传递，就可以更高效的表达信息。</p>
<p>编码的出现其实也意味着人们对信息的控制（熵减）——因为编码的表达（例如动作，叫声）本身，也是编码的一部分，都属于某种小概率的行为。但当这种行为被赋予编码的含义，反过来也意味着这种行为的出现频率将会变高，于是这种行为的熵变小，进而可预测性提升。</p>
<p>编码不仅仅是对客体的描述，也是对客体的控制，进而在局部可以逆转 <sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> 热力学第二定律。因为<strong>编码意味着一种控制行为，也就带来了可预测性的提升</strong>。</p>
<p>这个结论也昭示了本文的核心观点：好的编码才是 LLM 进行预测的关键。</p>
<blockquote>
<p>这也是为何 LLM 最早在 NLP 和 Coding 领域取得成功，因为这两者背后都依托于非常良好的编码。</p>
</blockquote>
<h4 id="编码的质量">编码的质量</h4>
<p>有了编码的帮助，生物就可以更好的控制自身和外部环境之间的交互，让原本更加随机不可控的生存，变得更加可控了。而这种控制的方式，就是通过编码，让随机事件中的小概率变得不那么随机（更有确定性），系统的熵降低了，但被编码的事件（信息）的熵 <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> 增加了。</p>
<p>所以系统更加可预测 -&gt;系统的熵降低 -&gt;信息编码的熵增加。</p>
<p>其实这件事在香农的信息论里本来就是比较显然的结果——更好的编码是按照信息的熵值大小进行编码的。甚至所谓的“压缩即智能”中的算术编码，也是自然的香农信息论的编码结果。</p>
<h2 id="编码的演进">编码的演进</h2>
<p>如果客观世界是无法被改变的，那么最优的编码是固定的，几乎不存在编码的选择问题。</p>
<p>不过编码是主观的，是生物控制自身适应环境的工具。所以编码是不断演进的，甚至编码本身的演进就是一种控制客观存在的能力的提升（例如计算机代码）。</p>
<p>所以我们需要从演进的视角来观察编码变化带来的价值，进而了解我们需要怎样的编码来更好的进行预测和控制。</p>
<h3 id="一些编码演进的案例">一些编码演进的案例</h3>
<blockquote>
<p>[!example] 从成语看语言的演进</p>
<p>各种语言的演进都是从拟声词开始的，而且这种能力并不是人类所独有，很多生物都会有自己的一些独特的信息编码表达（包括不同的叫声，也包括用排泄物标识领地等等）。</p>
<p>相比于动物，人类的独特之处在于创造了更多的编码，并开始组合使用这些编码。于是很多简单概念的编码就连接起来，形成了句子，形成了语言。</p>
<p>有了语言以后，人们就有能力更加便捷的传播信息，于是很多信息打包在一起，形成了故事，再进行传播。而这里则又出现了一次重要的编码演化——当故事传播后，它自身就成了一个编码，蕴含了远比普通的拟声表达、简单词语、句子更加丰富的内容。</p>
<p>这种组合，在不同的语言不同的地域有不同的表现形式，有的叫典故、有的会形成歇后语、而在汉语中，运用了一种比较独特的编码形式——<strong>成语</strong>，用四个字的方式将大量的类似的故事进行编码和传播，进一步提升了汉语的熵。</p>
<p>并且有了成语这种编码，再回到一般的语言表达时，句子的信息含量也得到极大的提升，甚至可以通过多个成语，再次形成新的成语，不断演进这个过程。</p>
</blockquote>
<blockquote>
<p>[!example] <code>Python</code> 和 <code>JavaScript</code></p>
<p>单从语言效率的方面来评判，<code>Python</code> 和 <code>JavaScript</code> 都算不得是很优秀的编程语言。但近些年，这两种编程语言却超越了传统的 <code>C</code>、<code>C++</code> 和 <code>Java</code>，成为了最流行的编程语言，这背后也是编码演进的功劳。</p>
<p>首先，<code>Python</code> 和 <code>JavaScript</code> 语言最大的特点都是入门简单，于是先天就会都拥有大量的普通用户。普通的用户对于编程语言没有很专业的训练，更需要的是简单快速可实现的能力，于是正应对上了 <code>Python</code> 和 <code>JavaScript</code> 发展中最重要的能力——包管理。</p>
<p>一个 <code>Python</code> 项目或者 <code>JavaScript</code> 项目，往往都会伴随一个巨大的第三方依赖文件夹，用 <code>pip</code> 或 <code>npm</code> 在项目中引入了巨量的代码，但对用户而言，在使用编程语言时，对于大量复杂的功能的使用，则只需要简单的接口或者函数就能实现，而不再需要关心各种通用功能的细节，让普通用户也可以实现复杂而高级的能力。</p>
<p>这种包引用的方式，其实就是编程语言的一种演进——将大量复杂的信息组合后，用新的编码来替代，就可以让编码的熵得到提升，进而让普通人也可以使用上（预测出）更可控的编码来控制外部世界。这个例子的说明了，好的编码确实可以让编码的预测性变得更好。</p>
<p>更直接的例子，现在无论哪种编程语言，进行数学计算时，都会直接用数学表达式进行表达，而不会用汇编将每一次的加法进行各种位移操作。这样才使得我们操控编码变得更加有效。</p>
</blockquote>
<blockquote>
<p>[!example] 数学</p>
<p>数学的发展史是极度依赖数学符号（编码）的演进的。今天的人可以比古人更明白数理，数学符号（编码）功不可没。</p>
<p>数学符号发展的第一步是从数演变成数字——即用具体的编码来指代不同的数量，而不是用数量本身来指代数量。这种变化才能让人类对数量的认知从 $10$ 以内（手指的数量），扩充到更多。</p>
<p>有了数字后，下一个重要的演进则是用不同的位置来标识不同的数字，也就是我们现在熟悉的进位制。这之后，大量级的数字才有机会被统计和计算，人类才真正将数学变成一个工具。</p>
<p>然后是分数的概念 <sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>。或者更准确的说法，是除法的出现和表达。人们终于可以一定程度上在连续的数域上进行管理和控制。</p>
<p>虽然第一次数学危机引入了无理数，对数学史意义重大，但从数学的发展来看，无穷的出现和编码，才是真正的突破。有了对于无穷的理解，才有了后来牛顿的微积分（牛顿对于微积分的最重要贡献也是微积分的符号），数学才步入了近代的发展。</p>
<p>这之后，人们愈发理解了数学符号对数学发展的重要性，数学符号的演进也是飞速的，不再成为数学发展的掣肘。</p>
</blockquote>
<blockquote>
<p>[!example] 技术的演进</p>
<p>技术的演进其实也是编码化的——每一种新的技术都会有自己的编码描述，然后各种新技术（编码）进行重组，又会形成新的编码，提升技术的熵值，让人们可以控制更加难以控制（自然发生的概率更小）的事物。</p>
<p>例如元素周期表的出现就极大推动了化工以及材料、健康、能源、农业等相关产业的发展。元素周期表之前，少数的化学家也可以掌握一些物质的性质和信息，但组合使用是需要极高的门槛的。有了元素周期表，有了化学物质的新命名方式，以及更容易计算的化学反应方程，对于普通高中生而言一般的化学变化都可以轻松掌握。</p>
<p>类似的，每一种技术的发展，其实背后都是对应的编码的演进过程。如前面 <code>Python</code> 和 <code>JavaScript</code> 的例子是这样；工业生产、供养链、产业带的演进等等都是这样的过程。所以最终技术的成功不依赖于最初技术编码设计的是否巧妙，而是在于技术编码演进的过程中，对应的编码是否逐渐拥有了更大的熵。</p>
<p>以当下人类工业的顶点——光刻机为例，组装光刻机的企业并不掌握全部的工业技术，而是掌握了很多的技术编码，对编码进行组装；而上游的很多企业也只掌握了特定编码的生产，甚至也是更低级编码的组装。但足够复杂的编码构成，最终才形成了现在的可以按纳米级控制生产原件的机器的诞生。</p>
</blockquote>
<h3 id="编码的进化">编码的进化</h3>
<p>我们如何进一步提升编码的信息熵，让编码变得更好？从上文的几个案例中，其实可以找到一些共通点。</p>
<p>编码是需要不断组合，进而形成更加高级的概念。由此不断的可以控制客观发生概率更小的事情。</p>
<blockquote>
<p>客观的物理世界中随机出现一个 <code>iPhone</code> 手机基本是不可能的。我们人类是如何通过编码的控制创造了批量制造 <code>iPhone</code> 的方式呢？</p>
<p>我们需要 <code>集成电路</code> 这个编码，需要 <code>电池</code> 这个编码，需要 <code>高清屏幕</code> 这个编码，同时这些编码也不是天然存在的，是更往前的历史长河中，由更加基础的编码组合而成的。</p>
<p>所以当我们需要 <code>iPhone</code> 时，会拆解成 <code>集成电路</code>、<code>电池</code>、<code>高清屏幕</code>、……等等的概念，而这些概念继续拆解，直至拆解到类似于 <code>硅</code>、<code>胶水</code>、<code>玻璃</code> 等等相对基础的编码，用流程化的工程手段一步步组合成最终的高级的 <code>iPhone</code> 手机。这些编码就是人们控制生产的完整流程，有了这些编码组合，生产出 <code>iPhone</code> 就变成了一件确定性，可预测的时间了。</p>
</blockquote>
<p>编码进化的方式遵循着进化的三条基本规则：</p>
<ul>
<li><strong>自然选择</strong>：被使用得更多（概率更大）的编码会被保留下来；</li>
<li><strong>基因漂变</strong>：某一个编码的对应的信息会小幅度的进行一定程度的变化，以更好的适应自然选择；</li>
<li><strong>基因重组</strong>：形成新的编码的更高效的方式，就是两个已经存在的编码进行一定程度的关联，如果能够顺利关联上，就可以快速组合出新的优质编码。</li>
</ul>
<h3 id="编码不是信息组合">编码不是信息组合</h3>
<p>从前面的分析，我们知道高级的编码是很多低级编码的组合，因此蕴含了极大的信息熵，从而更好的控制了客观世界。</p>
<p>那么编码仅仅是信息打包的组合吗？或者更具体的说，人们使用编码的时候，需要能完全的理解编码背后的全部低级编码组合吗？令人庆幸的是，并不需要。当一个编码形成后，编码自身就已经是独立的控制手段了。大家可以通过编码交流，但并不需要完整的交流编码背后的全部信息，即可实现信息和控制的传递。</p>
<blockquote>
<p>关于中心极限定理，其数学表达和证明并不是很显然的，也不是未经训练的人就可以快速掌握的。</p>
<p>但它的直接结果：<code>正太分布</code>，却可以十分常见的应用于人们对外部世界的控制。</p>
</blockquote>
<p>所以编码本身不能简单的看作是信息组合的标识符，编码存在本身就已经意味着重要的意义。</p>
<h3 id="进化的结果是熵减更可控">进化的结果是熵减（更可控）</h3>
<p>编码的意义是指向一块小概率（自然发生的概率）的空间；通过编码进行的控制其实就是意欲将解空间限制在这块空间附近，进而提升解落在这块空间中的概率。于是编码就带来了熵减，而从应用的角度来理解，就是编码对应的行为更可控（可预测）。</p>
<p>而编码的进化过程，则是一种可持续的熵减演进的过程，带来结果的更加可控和可预测。</p>
<p>反过来这也说明了，哪怕是同一种编码，经过了不断进化后，也会提升其可预测性。这其实也反映了 LLM 的能力是收到编码的制约的——编码本身提供了可预测性的天花板。糟糕的编码 <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> 在 LLM 中也很难取得突出的效果。</p>
<h2 id="编码与-llm">编码与 LLM</h2>
<p>LLM 的目标和能力是对编码进行预测。通过上文的分析，我们已经知道，编码的作用原本就是是为了生物控制外界而诞生的；同时编码的演进方向其实也正是为了让编码变得更容易预测（增大解空间）。所以：</p>
<ul>
<li>好的 LLM 可以很好的复原编码的预测性（LLM 可以像人一样使用编码）；</li>
<li>好的编码可以提升 LLM 的可预测性；</li>
</ul>
<h3 id="语言编码">语言编码</h3>
<p>语言编码是当下最适合 LLM 的编码。也正如我们感受到的一样，LLM 在单纯的语言能力方面，已经达到甚至超过了人的能力。</p>
<p>因为语言编码经过千万年的演进，已经是一个比较优良的编码了。也正是因为这个原因，LLM 才被称为 Language 模型，而不是一个编码模型。</p>
<p>甚至可以说，在语言编码方面，LLM 已经进化到了极致——对编码本身的利用率已经几乎压榨到底了。甚至并不需要特别大的模型，就可以很好的利用语言编码的能力了（例如 14b 以下的小模型）。</p>
<h3 id="code-编码">Code 编码</h3>
<p>编程语言是人类设计出来的编码，同时参考了很多自然语言的用法和逻辑，尤其是有了包管理的概念后，Code 编码的演进速度甚至超过了语言编码。加上 Code 的语法相比语言更加严格（解空间更小），带来的熵减也比语言编码更多一些，所以具有更好的可预测性（可控性）。</p>
<p>所以 LLM 对 Code 编码的利用能力也是各种编码中最好的。面向未来的话，利用 LLM 解决 Coding 相关问题的能力一定也将会是率先迎来突破的领域（Cursor 已经初步展示了这种能力，并不需要利用更大的 LLM，现有的 LLM 甚至更小的都足够完成这种能力上的质变）。</p>
<h3 id="数学编码">数学编码</h3>
<p>数学的逻辑推理其实是十分严格的编码语言，同时数学的各种定理也足以构成更高级的编码。在这个意义上来说，数学编码将会是未来能取得重要突破的领域。</p>
<p>当下的问题是，lean 语言作为数学的编码，其语料太少，非常多的基础定理都还尚未被 lean 语言描述出证明过程。这使得 LLM 可利用的编码所蕴含的熵很少，所以可预测性很低。</p>
<p>类似于人做证明题，如果掌握了很多的定理，很多题目都会很显然。但如果没有任何的定理，所有数学命题都只能从定义出发进行推理，那么这件事将会变得非常的难。</p>
<p>而通过 lean 语言进行数学推理，DeepMind 利用强化学习，已经在几何领域中给出了成功的案例：通过强化学习生成更多的新的编码，然后学习如何利用新的编码，就可以掌握更加复杂的推理过程。</p>
<h3 id="多模态编码">多模态编码</h3>
<p>当前的多模态编码完全是一种无语意的数字化编码，而且以现在关于多模态的使用方式来看，这种编码也不具备进化的能力。所以注定多模态大模型大概率不会有什么突破性的能力出现，做到极致也仅仅是远弱于人的理解能力。</p>
<p>其实早期的 CV 研究，还是在沿着如何更好的对图像信息编码，甚至将编码不断演进的路子前行的。但后来在深度学习出现后，直接黑盒进行判别模型取得了远比编码的方式更优越的结果，就让大家逐渐放弃了编码这条路。</p>
<p>其实今天的 LLM 带给我们的关于 CV 的启示是，或许编码这条路没有错，仅仅是曾经的我们在这条路上走得还不够远。一些关于视觉方面更好的编码特征，可能才能让多模态大模型迸发全部的能量。</p>
<p>甚至更具体的说，如何能将多模态的编码与语言编码真形成对应（这就是人类或者动物真实完成的事情），然后更好的利用语言编码的能力，才能让多模态发挥更大的价值。</p>
<blockquote>
<p>更好的预测，意味着需要在原本真实物理体系的解空间中增加更多的限制，缩小解空间。单纯的图像信息不经过更好的编码是很难做到这件事情的。例如我们看到猫在跑，因为这是“猫”，所以它才会有“猫”独特的行为方式和风格，我们才得以对“猫”进行了预测。</p>
<p>如果我们不能将图像对应到“猫”这样的语言编码上，那么图像的解空间是无法被控制的，预测性就大打折扣。</p>
</blockquote>
<h3 id="agent-编码">Agent 编码</h3>
<p>大语言模型在提升生产力方面最大的想象空间就是 Agent。但诸多的实践都让我们发现，真实场景下，Agent 解决问题的能力非常的有限，远不及不使用大模型的传统自动化手段更高明。</p>
<p>其实这个世界中如此之多的自动化，如此之多的控制，都意味着这里天然存在某一种编码，才实现了对应的控制能力（极大的熵减）。</p>
<p>大模型之于 Agent 的核心问题，是在于现在没有一套合适的编码将各种控制手段简单直接的描述出来 <sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>。如果有更加适合的语言来描述 Agent 的控制，则可以更快的推进 Agent 的发展，真的让 LLM 带来大幅的生产力的提升。</p>
<blockquote>
<p>如果从人的实践经验来类比，SOP 就比普通的自然语言更适合作为行为指引的编码，有效的控制了解空间的大小。</p>
</blockquote>
<p>现有的相关的编码注重的都不是信息熵的多少，而是偏操作的可解析性，容错性等问题。（例如 Json，或者 AutoGPT 的每一步的结果等等）。</p>
<p>这方面来说，或许从 Todo 体系 <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> 出发，设计一套可以引入包管理的更有利于 Agent 的编码，会是更好的解决方案。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>现在看来，这样的理解也确实有一定的问题，核心并不是压缩率，而是通过使用编码带来的熵减。&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><strong>不可计算</strong>是指，无法通过数据点复原动力方程。真实世界中<strong>不可计算</strong>是普遍现象，三体问题就是最简单而经典的不可计算的例子。&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>热力学第二定律本身是一个全局的物理学定律，任何物质的运动都无法脱离于物理学存在，所以热力学第二定律是不存在真正的所谓的“逆转”的。但在局部环境下，是可以通过一些控制手段，将这些局部的熵值降低的；所付出的代价一般是对外释放了更多的热能，进而让全局的熵值变得更大了。一些具体的例子：电冰箱；星云中形成恒星等等。&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>信息熵大，意味着这件事更难被描述，也就是客观随机发生的概率更小。而原本随机发生概率小的事被控制以更大的概率发生，则意味着系统上的降低。&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>小数的概念要晚很多，而且小数不仅依赖分数的概念，还依赖无穷、近似等等很多数学概念的诞生。&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p>在我看来多模态的大部分编码都属于糟糕的编码。语言模型在文字水平上达到甚至超越了人，但多模态模型远不及人类的能力；以及，多模态对于 AGI 将会毫无帮助，它的编码是无法进化的，除非转化为语言。&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p>很明显人类的语言并不是自动化控制的适合编码，其中无效的信息过多，编码的熵太小。编程语言也充斥了过多的控制细节，编码的熵相对于这件事也太低。&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p>我的另一个项目就在设计类似这样一个编码。还是回到编码演化的话题，这件事不在于编码设计得有多好，而在于编码是否能持续不断的获得更好的演化。例如如果能将很多智能家居的自动化流程传唤成某种编码，那就积累了大量的使用场景和数据，自然这种编码对应的熵减就会很大，编码就更容易带来好的结果。&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
]]></content:encoded>
    </item>
  </channel>
</rss>
