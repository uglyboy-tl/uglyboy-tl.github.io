<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>大语言模型原理分享 | 拾柒读库</title>
<meta name=keywords content="LLM"><meta name=description content="什么是大语言模型？ 当我说了很多话之后，我马上要说$\Box$ 数学公式描述 $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ 预训练模型可以保证"><meta name=author content="癸老师"><link rel=canonical href=https://blog.uglyboy.cn/posts/test/><link crossorigin=anonymous href=/assets/css/stylesheet.0c4fd3725171366f335155acde6fb3c7b7042cd2fd075bebf5023d9b28a701b2.css integrity="sha256-DE/TclFxNm8zUVWs3m+zx7cELNL9B1vr9QI9myinAbI=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.uglyboy.cn/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.uglyboy.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.uglyboy.cn/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.uglyboy.cn/apple-touch-icon.png><link rel=mask-icon href=https://blog.uglyboy.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js></script><link href=https://cdn.bootcdn.net/ajax/libs/reveal.js/4.6.0/reveal.min.css rel=stylesheet><link href=https://cdn.bootcdn.net/ajax/libs/reveal.js/4.6.0/theme/moon.min.css rel=stylesheet><script src=https://cdn.bootcdn.net/ajax/libs/reveal.js/4.6.0/reveal.min.js></script><script src=https://cdn.bootcdn.net/ajax/libs/reveal.js/4.6.0/plugin/markdown/markdown.min.js></script><script src=https://cdn.bootcdn.net/ajax/libs/reveal.js/4.6.0/plugin/highlight/highlight.min.js></script><script src=https://cdn.bootcdn.net/ajax/libs/reveal.js/4.6.0/plugin/math/math.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){var e,t=document.querySelector("main.main");t.className="reveal",e=document.querySelector("header"),e&&(e.innerHTML=""),e=document.querySelector("footer"),e&&(e.innerHTML=""),Reveal.initialize({plugins:[RevealMarkdown,RevealHighlight,RevealMath.MathJax3]})})</script><link rel=stylesheet href=https://cdn.bootcdn.net/ajax/libs/lxgw-wenkai-webfont/1.6.0/style.min.css><style>body,code,section{font-family:lxgw wenkai,sans-serif}</style><meta property="og:title" content="大语言模型原理分享"><meta property="og:description" content="什么是大语言模型？ 当我说了很多话之后，我马上要说$\Box$ 数学公式描述 $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ 预训练模型可以保证"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.uglyboy.cn/posts/test/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-21T01:45:37+08:00"><meta property="article:modified_time" content="2023-12-06T17:20:12+08:00"><meta property="og:site_name" content="拾柒读库"><meta name=twitter:card content="summary"><meta name=twitter:title content="大语言模型原理分享"><meta name=twitter:description content="什么是大语言模型？ 当我说了很多话之后，我马上要说$\Box$ 数学公式描述 $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ 预训练模型可以保证"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"文章","item":"https://blog.uglyboy.cn/posts/"},{"@type":"ListItem","position":2,"name":"大语言模型原理分享","item":"https://blog.uglyboy.cn/posts/test/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"大语言模型原理分享","name":"大语言模型原理分享","description":"什么是大语言模型？ 当我说了很多话之后，我马上要说$\\Box$ 数学公式描述 $w_1, w_2,\\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\\dots,w_{N})=\\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\\dots,w_{i}) $$ 预训练模型可以保证","keywords":["LLM"],"articleBody":"什么是大语言模型？ 当我说了很多话之后，我马上要说$\\Box$\n数学公式描述 $w_1, w_2,\\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是：\n$$ p(w_{1},w_{2},\\dots,w_{N})=\\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\\dots,w_{i}) $$\n预训练模型可以保证文字的连贯性和合理性，但对于不具备响应指令的能力。 如果需要模型具有响应使用者指令的能力，所需要的是对预训练模型进行“人类指令对齐”。 更具体的说，就是通过一些样本和形式，让模型知道我们正在生成的是一段对话，而不是一段文章。 模型生成的是上一句话的回答。 模型只生成一次答复内容，不要在生成回答后，有继续生成下一段回答。 大语言模型能做什么？ 大模型能记住它看到过的一切信息。 大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。 大模型究竟能达到怎样的泛化能力？ 大模型可以涌现出智能吗？\n大语言模型不能做什么？ 大模型无法判别一个 $\\{[0|1]^*\\}$ 序列中是否有奇数个 $1$。 给定 $n$ 大模型无法生成 $(aa)^n$。 大模型无法判定 $\\{0^n\\#1^n\\}$ 形式的序列。 大模型无法执行加法运算。 $\\dots$ 大语言模型没有，也不可能具有推理能力。\n大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。\n大语言模型是如何将信息泛化的？ 通过相似度计算来进行泛化，然后通过概率分布来进行选择。 粗略的可以如下理解：可以用同义词替代的都能被泛化。 这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。 在训练样本充分的情况下，可以跨语言进行同义词泛化。 大语言模型的上下文长度又是怎么回事？ 为什么要限制上下文长度？ 在预训练阶段，我们所有的样本都是在 $4k-1$ 的长度下，让模型学习第 $4k$ 个文字。所以训练的模型只能在 $4k$ 范围内工作，因为更长的文本没有见过，通常设计的预训练模型也没有尝试让模型去理解更长的文字。\n导致这种情况发生的最核心的难点是，我们没有足够多的长文本作为训练样本。\n如何扩充到 $200k$ 我们对模型中的位置指针做了些调整，让 $200k$ 的字符指向 $4k$ 的字符，类似的每个 $200k$ 以内的位置都指向了 $4k$ 以内的一个相应的位置上。这样十分长的文本就可以被模型“误认为”是曾经见过的短文本了。 但这样处理，很多相对长度信息错乱，例如原本两个文本是相差3个词的，但在新的指向下，变成了 $3/50$ 个词，而且这样的位置指针是找不到对应信息的。所以我们构造了不那么多的 $200k$ 长的训练样本，来重新学习出新的位置指针下的模型。 会带来什么问题？ 语义上的位置信息与真实位置信息的对应关系有可能被混淆。 对位置信息的利用方面，会有一定的性能损失。 因为补充的 $200k$ 的样本主要都是小说，所以非小说的其他类型的上下文信息的使用，会被当作小说一样的使用。 这一点是迁移学习带来的弊端，如果实践当中遇到问题，未来有可能用其他方法来优化。 Q \u0026 A 大模型如何才能按照用户要求的 word counts 回复？用户有时要求回复的特别长，比如1万字，如何能做到？ 我们看到模型在榜单上的排名很高，不过在对话中感觉并没有排名低的“聪明”，大模型榜单和用户真实的体感有什么关系？ 大模型的prompt有没有标准的一套语法（类似代码的语法）用来控制？现在看起来大家都在发挥自己的文风 分享预告 RAG Agent 推理加速 $\\dots$ ","wordCount":"1264","inLanguage":"zh-cn","datePublished":"2023-11-21T01:45:37+08:00","dateModified":"2023-12-06T17:20:12+08:00","author":{"@type":"Person","name":"癸老师"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.uglyboy.cn/posts/test/"},"publisher":{"@type":"Organization","name":"拾柒读库","logo":{"@type":"ImageObject","url":"https://blog.uglyboy.cn/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.uglyboy.cn/ accesskey=h title="拾柒读库 (Alt + H)">拾柒读库</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.uglyboy.cn/ title=主页><span>主页</span></a></li><li><a href=https://blog.uglyboy.cn/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=https://blog.uglyboy.cn/tags/ title=标签><span>标签</span></a></li><li><a href=https://blog.uglyboy.cn/archives/ title=时间轴><span>时间轴</span></a></li></ul></nav></header><main class=main><div class=slides><section data-markdown><textarea data-template>
    
## 什么是大语言模型？

---

当我说了很多话之后，我马上要说$\Box$

---

## 数学公式描述

$w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是：

$$
p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i})
$$

---
- **预训练模型可以保证文字的连贯性和合理性，但对于不具备响应指令的能力。**
- 如果需要模型具有响应使用者指令的能力，所需要的是对预训练模型进行“人类指令对齐”。
- 更具体的说，就是通过一些样本和形式，让模型知道我们正在生成的是一段对话，而不是一段文章。
    - 模型生成的是上一句话的回答。
    - 模型只生成一次答复内容，不要在生成回答后，有继续生成下一段回答。
---

## 大语言模型能做什么？

---

- 大模型能记住它看到过的一切信息。
- 大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。

---

### 大模型究竟能达到怎样的泛化能力？

&gt; 大模型可以涌现出智能吗？

---

## 大语言模型不能做什么？

---
1. 大模型无法判别一个 $\\\{[0|1]^*\\\}$ 序列中是否有奇数个 $1$。
2. 给定 $n$ 大模型无法生成 $(aa)^n$。
3. 大模型无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列。
4. 大模型无法执行加法运算。
5. $\dots$

---

大语言模型没有，也不可能具有推理能力。

大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。

---

## 大语言模型是如何将信息泛化的？

---

- 通过相似度计算来进行泛化，然后通过概率分布来进行选择。
    1. 粗略的可以如下理解：可以用同义词替代的都能被泛化。
    2. 这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。
    3. 在训练样本充分的情况下，可以跨语言进行同义词泛化。

---

## 大语言模型的上下文长度又是怎么回事？

---
## 为什么要限制上下文长度？
在预训练阶段，我们所有的样本都是在 $4k-1$ 的长度下，让模型学习第 $4k$ 个文字。所以训练的模型只能在 $4k$ 范围内工作，因为更长的文本没有见过，通常设计的预训练模型也没有尝试让模型去理解更长的文字。

&gt; 导致这种情况发生的最核心的难点是，我们没有足够多的长文本作为训练样本。

---
## 如何扩充到 $200k$

- 我们对模型中的位置指针做了些调整，让 $200k$ 的字符指向 $4k$ 的字符，类似的每个 $200k$ 以内的位置都指向了 $4k$ 以内的一个相应的位置上。这样十分长的文本就可以被模型“误认为”是曾经见过的短文本了。
- 但这样处理，很多相对长度信息错乱，例如原本两个文本是相差3个词的，但在新的指向下，变成了 $3/50$ 个词，而且这样的位置指针是找不到对应信息的。所以我们构造了不那么多的 $200k$ 长的训练样本，来重新学习出新的位置指针下的模型。

---
## 会带来什么问题？
- 语义上的位置信息与真实位置信息的对应关系有可能被混淆。
- 对位置信息的利用方面，会有一定的性能损失。
    - 因为补充的 $200k$ 的样本主要都是小说，所以非小说的其他类型的上下文信息的使用，会被当作小说一样的使用。
    - 这一点是迁移学习带来的弊端，如果实践当中遇到问题，未来有可能用其他方法来优化。

---
# Q &amp; A

---
1. 大模型如何才能按照用户要求的 word counts 回复？用户有时要求回复的特别长，比如1万字，如何能做到？

---
2. 我们看到模型在榜单上的排名很高，不过在对话中感觉并没有排名低的“聪明”，大模型榜单和用户真实的体感有什么关系？

---
3. 大模型的prompt有没有标准的一套语法（类似代码的语法）用来控制？现在看起来大家都在发挥自己的文风

---
## 分享预告

- RAG
- Agent
- 推理加速
- $\dots$
    </textarea></section></div></main><footer class=footer><span>&copy; 2023 <a href=https://blog.uglyboy.cn/>拾柒读库</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制代码";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制代码"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>