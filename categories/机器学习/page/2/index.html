<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>机器学习 | 拾柒读库</title>
<meta name=keywords content><meta name=description content><meta name=author content="癸老师"><link rel=canonical href=https://blog.uglyboy.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><meta name=google-site-verification content="3G6_t7vAxMLWAnWZ3vEdzO31bCfdUbjWEHHCL_KDnjw"><link crossorigin=anonymous href=/assets/css/stylesheet.12d3050c0383b8fe83070e2bf48ca83339c46b207da8650cd35b45c866d40674.css integrity="sha256-EtMFDAODuP6DBw4r9IyoMznEayB9qGUM01tFyGbUBnQ=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.uglyboy.cn/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.uglyboy.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.uglyboy.cn/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.uglyboy.cn/apple-touch-icon.png><link rel=mask-icon href=https://blog.uglyboy.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://blog.uglyboy.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml><link rel=alternate hreflang=zh-cn href=https://blog.uglyboy.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://blog.uglyboy.cn/scss/main.min.bb0f243946b87c8f66307b9c43939ead878278180e8edada628b0d7ecd38edfc.css integrity="sha256-uw8kOUa4fI9mMHucQ5OerYeCeBgOjtraYosNfs047fw=" media=screen><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{enableExplorer:!1,skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/babel-polyfill/7.12.1/polyfill.min.js integrity="sha512-uzOpZ74myvXTYZ+mXUsPhDF+/iL/n32GDxdryI2SJronkEyKC8FBFRLiBQ7l7U/PTYebDbgTtbqTa6/vGtU23A==" crossorigin=anonymous referrerpolicy=no-referrer></script><script crossorigin=anonymous integrity="sha512-6FaAxxHuKuzaGHWnV00ftWqP3luSBRSopnNAA2RvQH1fOfnF/A1wOfiUWF7cLIOFcfb1dEhXwo5VG3DAisocRw==" src=https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.min.js></script><link crossorigin=anonymous integrity="sha512-YZW7jSV4QrwpPzFxB77lAW4qNIeS6RaipaStONrpmbJsyh3zxM/3VoeQrrGlYkNS5nIjsKFURRHnsKhmE/vWmg==" href=https://lib.baomitu.com/lxgw-wenkai-webfont/latest/style.min.css rel=stylesheet><style>body,section{font-family:lxgw wenkai,sans-serif}</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-0T89SF4PSW"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-0T89SF4PSW")</script><meta property="og:url" content="https://blog.uglyboy.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="拾柒读库"><meta property="og:title" content="机器学习"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="机器学习"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.uglyboy.cn/ accesskey=h title="拾柒读库 (Alt + H)">拾柒读库</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.uglyboy.cn/posts/ title=文章><span>文章</span></a></li><li><a href=https://blog.uglyboy.cn/slides/ title=演示><span>演示</span></a></li><li><a href=https://blog.uglyboy.cn/categories/ title=分类><span>分类</span></a></li><li><a href=https://blog.uglyboy.cn/tags/ title=标签><span>标签</span></a></li><li><a href=https://blog.uglyboy.cn/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=https://blog.uglyboy.cn/archives/ title=时间轴><span>时间轴</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>机器学习
<a href=/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>大模型的计算能力</h2></header><div class=entry-content><p>## 大语言模型的计算能力 --- ### LLM 的几个核心数学问题 ----- 1. N-GRAM 的计算能力问题 2. 过参数化模型的统计学习问题 3. 非凸的数值优化问题 4. 对深度神经网络的数学理解 5. Transformer 算子的含义 6. fine-tuning 的数学含义 --- ### N-GRAM 的计算能力 --- - **大语言模型的基本范式：** - 假设 $w_1, w_2,\dots, w_{N}$ 是一个单词序列。我们可以按如下公式计算单词序列的概率： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ - 该模型是一个 $N-1$ 阶的马尔可夫链，称为 `N-GRAM` 模型。 - 该模型的计算能力是有限的，因为它的是个有穷自动机。 --- - `非确定型有穷自动机`(`NFA`) 是一个 5 元数组 $Q,\Sigma,\delta,q_0,F$，其中 - $Q$ 是一个有穷集合，称为**状态集**。 - $\Sigma$ 是一个有穷集合，称为**字母表**。 - $\delta:Q\times\Sigma_\varepsilon\rightarrow \mathcal{P}(Q)$ 是**转移函数**。 - $q_0\in Q$ 是**起始状态**。 - $F \subseteq Q$ 是**接受状态集**。 --- #### 大模型是有穷自动机的证明过程 ----- - 令 $q_0 =\varepsilon$ 为初始状态，大语言模型的预测函数记为 $$ \phi:\{s_0s_1s_2...s_{n-1}\}\rightarrow s_n,s_i \in \Sigma $$ - 取 $\delta$ 为： $$ \begin{equation} \delta(q,\sigma) = \left \\\{ \begin{array}{ll} q \circ\sigma & \sigma \neq \varepsilon\\\\ q \circ\phi(q) & \sigma = \varepsilon \end{array} \right. \end{equation} $$ - 也就是将 $Q$ 设置为已经拥有的上文，持续输入或预测下一个字符。 --- - 在 [Bhattamishra et al. 2020](https://arxiv.org/abs/2009.11264) 中也有类似的实验，实验中基于 Transformer 的大语言模型甚至只能识别弱化的正则语言。 - 大模型无法判别一个 $\{[0|1]^*\}$ 序列中是否有奇数个 $1$。 - 给定 $n$ 大模型无法生成 $(aa)^n$。 - 在 [Zhou et al. 2023](http://arxiv.org/abs/2310.16028) 中还尝试论述了基于 Transformer 的大语言模型也无法实现加法运算之类的复杂运算。 - 以及，有穷自动机无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列；也无法进行基础的四则运算（无法处理括号的闭合和乘法的优先顺序）。 --- ### 大模型计算能力是有限的 ----- - 大模型不具备推理能力，这件事与模型的规模无关。 - 大模型是通过语言概率分布的泛化来模拟出推理能力的假象。 - 例如：大模型不会数数。他只是把看到过的数数类型的答案都记住了，然后用类比的方式去回答新的问题；如果答案在记忆中，就会回答正确。 - 更大的模型可以记住更多的答案，但是这并不是我们想要的答案。 - 我们需要新的范式来解决 AGI 问题。 --- ### Agent + LLM 可以成为完备图灵机 --- - Agent 的基本范式是一个 While 程序。 - 例如下面几种常见的 Agent： 1. [ReAct](http://arxiv.org/abs/2210.03629) 获得反思推理能力 2. [BabyAGI](https://github.com/yoheinakajima/babyagi) 基础的计划任务 Agent 3. [Reflexion](http://arxiv.org/abs/2303.11366) 长期记忆和短期记忆（短期记忆就符合上述流程） 4. [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) 第一个全能 Agent --- - 代码示例： ```python @dataclass class ReAct(ABC): thought: Optional[str] = None action: Optional[str] = None def __post_init__(self): self.obs = self.run() # 获取执行 Action 的结果 act = ReAct() acts = [] while not act.done: acts.append(act) prompt = get_prompt(acts) act: ReAct = ReAct.parse(llm.call(prompt)) # 调用大模型 ``` --- #### 编程语言 WHILE 语义 (Semnatik) ----- - 一个 while 程序 $P$ ,通过传递 $k$ 个参数,返回一个结果, 即 $f:\mathbb{N}^k\rightarrow\mathbb{N}$ - 其他未定义的参数可以在程序里被调用,但是必须设定为 $0$ - WHILE 程序的结果在结束结束后通过 $x_0$ 传达 - 对于一个 WHILE 程序,有三种运行模式: - 变量赋值: $x_i=x_j+c,c\in\{0,1,−1\}$ - $P_1$;$P_2$ ( $P_1$,$P_2$ 是两个任意程序程序),先运行 $P_1$ ,再运行 $P_2$ - WHILE $x_i \neq 0$ DO $P$ END 意思是, $P$ 程序将一直被运行,直到 $x_i$ 等于 0 --- - **定理：编程语言 WHILE 是图灵完备的** - **证明:** 我们将受限 RAM(Registermaschine)(只有 LOAD,STORE,CLOAD,CADD,CSUB 功能的 RAM) 中的每一步都用 WHILE 程序来代替计算，由于受限 RAM 是图灵完备的,所以 WHILE 也是图灵完备的。 - 证明细节参看：[while循环](https://zhuanlan.zhihu.com/p/343107128) ，源自 [Unentscheidbarkeit des Halteproblems: WHILE-Programm, Vorlesung 10 in BUK von RWTH Aachen](https://algo.rwth-aachen.de/Lehre/WS1920/BuK/BuK/h10.pdf) --- - 实现图灵完备的方法不是唯一的。例如，[Schuurmans 2023](http://arxiv.org/abs/2301.04589) 就证明了，当可以使用外部存储时，大模型是图灵完备的。 - 但是，这并不意味着 Agent + LLM 就是 AGI，毕竟我们现在的电脑本身就是图灵完备的，但是我们并不认为电脑就是 AGI。 - 我们需要的是一个可以自适应的 Agent，而不是一个固定的 Agent。也就是可以通过学习来改变自己的行为，而不是通过人工的方式来改变自己的行为。 --- ### 以整数加法为例 ----- > 我们希望 Agent 学会整数加法。但学会的方式不是我们给了它加法的程序让它执行，而是通过加法的真值，“推导”出加法的程序。模拟人做加法的方式，我们尝试让机器训练出加法程序 --- - **已知**： - 十以内的加减法（这部分的结果是背下来的）； - 用字符串来保存十进制的数字； - 有额外的存储可以利用（保存进位时的信息）； - **目标：** - 懂得如何利用已知的十以内的加减法的结果，进行多位的加减法运算； - 计算时需要从后向前计算； - 需要保留进位的信息； - 确保计算结果一定是准确的； --- - 这应该是一个强化学习的过程——只有计算正确时，才会获得奖励。其中，尝试探索的动作空间是： - 如何利用十以内的加减 - 通过怎样的计算顺序 - 如何利用额外的存储 - 最终以此来生成一个完整的加法运算流程。 --- ### 使用 RL 训练 Agent ----- Agent 的 While 循环模式恰好符合 Bellman 方程的形式。 --- > 通过强化学习训练 Agent，直观上，状态空间和奖励都不难定义，难的是究竟如何定义 Action 空间。 --- - 例如十以内的加减法为什么可以成为加法的 Action？ - 进一步，当我们尝试训练乘法时，九九乘法表一定在我们的 Action 空间中，那如何凭空让机器找到这个“九九乘法表”呢？ - 甚至计算乘法时，加法也需要在 Action 空间中。这意味着，强化学习能学会内容是有序的，而且 Action 空间的生成也是依赖之前的训练结果的。 - 这个结果并不意外，《技术的本质》一书中就提到过人类技术的发展是渐进的，而不是突变的。 --- > 牛顿无法简单的通过阅读代数和几何来发明微积分。问题是，要生成全新的想法，还缺什么？ **有可能达成 AGI 的新范式应当需要 Agent + LLM 的联合训练，而不是各自的单独训练。** --- ## Thanks</p></div><footer class=entry-footer><span title='2023-11-21 01:45:37 +0800 CST'>2023-11-21</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 大模型的计算能力" href=https://blog.uglyboy.cn/slides/2023/11/21/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>大语言模型原理分享</h2></header><div class=entry-content><p># 大语言模型&lt;br>原理分享 --- ## 什么是大语言模型？ --- 当我说了很多话之后，我马上要说 $\Box$ --- ## 数学公式描述 ----- $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ --- ## 大语言模型能做什么？ --- - 大模型能记住它看到过的一切信息。 - 大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。 --- ### 大模型能达到怎样的泛化能力？ > 大模型可以涌现出智能吗？ --- ## 大语言模型不能做什么？ --- 1. 大模型无法判别一个 $\\\{[0|1]^*\\\}$ 序列中是否有奇数个 $1$。 2. 给定 $n$ 大模型无法生成 $(aa)^n$。 3. 大模型无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列。 4. 大模型无法执行加法运算。 5. $\dots$ --- 大语言模型没有，也不可能具有推理能力。 > 大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。 --- ## 大语言模型是如何将信息泛化的？ --- - 通过相似度计算来进行泛化，然后通过概率分布来进行选择。 1. 粗略的可以如下理解：可以用同义词替代的都能被泛化。 2. 这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。 3. 在训练样本充分的情况下，可以跨语言进行同义词泛化。 --- # Q & A</p></div><footer class=entry-footer><span title='2023-11-21 01:45:37 +0800 CST'>2023-11-21</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 大语言模型原理分享" href=https://blog.uglyboy.cn/slides/2023/11/21/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>大语言模型的数学理解</h2></header><div class=entry-content><p>大语言模型的基本逻辑 大语言模型的本质是一个 N-GRAM 模型，即：
定义：
假设 $w_1, w_2,\dots, w_{N}$ 是一个单词序列。我们可以按如下公式计算单词序列的概率：
$$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$
该模型是一个 $N-1$ 阶的马尔可夫链，称为 N-GRAM 模型
...</p></div><footer class=entry-footer><span title='2023-11-09 12:08:22 +0800 CST'>2023-11-09</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 大语言模型的数学理解" href=https://blog.uglyboy.cn/posts/2023/11/09/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>大语言模型的计算能力</h2></header><div class=entry-content><p>大模型是有穷自动机 非确定型有穷自动机（NFA）的定义 非确定型有穷自动机是一个 5 元数组 $Q,\Sigma,\delta,q_0,F$，其中
$Q$ 是一个有穷集合，称为状态集。 $\Sigma$ 是一个有穷集合，称为字母表。 $\delta:Q\times\Sigma_\varepsilon\rightarrow \mathcal{P}(Q)$ 是转移函数。 $q_0\in Q$ 是起始状态。 $F \subseteq Q$ 是接受状态集。 大模型是 NFA 的证明 令 $q_0 =\varepsilon$ 为初始状态，大语言模型的预测函数记为
...</p></div><footer class=entry-footer><span title='2023-10-30 07:50:00 +0800 CST'>2023-10-30</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 大语言模型的计算能力" href=https://blog.uglyboy.cn/posts/2023/10/30/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>所谓“压缩即是智慧”毫无意义</h2></header><div class=entry-content><p>算数编码才是压缩的本质 一直以来，大家对于大模型的理解都接受了“压缩即是智慧”这个思想，这个想法源自 Compression for AGI - Jack Rae | Stanford MLSys #76
里面核心模式只有一个：
假定我有一个程序 f，我将 f 的代码传输给另一端； 我有一个序列需要传输，我通过 f 对逐个字符出现的概率进行了预测； 我根据算数编码，将结果编码后，传输给了另一端； 最后传输的信息量最小。 这不过是算数编码的定义好不好！！！ 哪里有什么神奇的地方。。。
...</p></div><footer class=entry-footer><span title='2023-10-25 10:57:47 +0800 CST'>2023-10-25</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 所谓“压缩即是智慧”毫无意义" href=https://blog.uglyboy.cn/posts/2023/10/25/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Scaling Law 的数学解读</h2></header><div class=entry-content><p>Dataset Size 和 Loss 的关系 最大似然估计（MLE） 一切机器学习的本质都是最大似然估计：
模型下的理想真实世界的概率分布：$p(x|\theta)$
我们不知道真实世界的分布，所以我们要用样本估计似然函数 $L(\theta|x)$
...</p></div><footer class=entry-footer><span title='2023-10-10 11:50:00 +0800 CST'>2023-10-10</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to Scaling Law 的数学解读" href=https://blog.uglyboy.cn/posts/2023/10/10/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://blog.uglyboy.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>«&nbsp;上一页&nbsp;
</a><a class=next href=https://blog.uglyboy.cn/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/page/3/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://blog.uglyboy.cn/>拾柒读库</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>