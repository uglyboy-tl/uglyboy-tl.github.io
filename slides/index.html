<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>演示 | 拾柒读库</title>
<meta name=keywords content><meta name=description content="演示 - 拾柒读库"><meta name=author content="癸老师"><link rel=canonical href=https://blog.uglyboy.cn/slides/><link crossorigin=anonymous href=/assets/css/stylesheet.d73d5a01dbf379e7897a3627eff85bf83c060878b9f292d177847340a76d2c8d.css integrity="sha256-1z1aAdvzeeeJejYn7/hb+DwGCHi58pLRd4RzQKdtLI0=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.uglyboy.cn/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.uglyboy.cn/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.uglyboy.cn/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.uglyboy.cn/apple-touch-icon.png><link rel=mask-icon href=https://blog.uglyboy.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://blog.uglyboy.cn/slides/index.xml><link rel=alternate hreflang=zh-cn href=https://blog.uglyboy.cn/slides/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://blog.uglyboy.cn/scss/main.min.bb0f243946b87c8f66307b9c43939ead878278180e8edada628b0d7ecd38edfc.css integrity="sha256-uw8kOUa4fI9mMHucQ5OerYeCeBgOjtraYosNfs047fw=" media=screen><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{enableExplorer:!1,skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/babel-polyfill/7.12.1/polyfill.min.js integrity="sha512-uzOpZ74myvXTYZ+mXUsPhDF+/iL/n32GDxdryI2SJronkEyKC8FBFRLiBQ7l7U/PTYebDbgTtbqTa6/vGtU23A==" crossorigin=anonymous referrerpolicy=no-referrer></script><script crossorigin=anonymous integrity="sha512-6FaAxxHuKuzaGHWnV00ftWqP3luSBRSopnNAA2RvQH1fOfnF/A1wOfiUWF7cLIOFcfb1dEhXwo5VG3DAisocRw==" src=https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.min.js></script><link crossorigin=anonymous integrity="sha512-YZW7jSV4QrwpPzFxB77lAW4qNIeS6RaipaStONrpmbJsyh3zxM/3VoeQrrGlYkNS5nIjsKFURRHnsKhmE/vWmg==" href=https://lib.baomitu.com/lxgw-wenkai-webfont/latest/style.min.css rel=stylesheet><style>body,section{font-family:lxgw wenkai,sans-serif}</style><meta property="og:url" content="https://blog.uglyboy.cn/slides/"><meta property="og:site_name" content="拾柒读库"><meta property="og:title" content="演示"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="演示"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"演示","item":"https://blog.uglyboy.cn/slides/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.uglyboy.cn/ accesskey=h title="拾柒读库 (Alt + H)">拾柒读库</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.uglyboy.cn/posts/ title=文章><span>文章</span></a></li><li><a href=https://blog.uglyboy.cn/slides/ title=演示><span class=active>演示</span></a></li><li><a href=https://blog.uglyboy.cn/categories/ title=分类><span>分类</span></a></li><li><a href=https://blog.uglyboy.cn/tags/ title=标签><span>标签</span></a></li><li><a href=https://blog.uglyboy.cn/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=https://blog.uglyboy.cn/archives/ title=时间轴><span>时间轴</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>演示
<a href=/slides/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Agent 使用指南</h2></header><div class=entry-content><p>## Agent 使用指南 --- ### 如何在真实世界中使用大模型？ > 我说想开灯，大模型能帮我开灯吗？ --- - 我们希望大模型能够直接的解决问题 - 这样的使用方法现在被人们称为： **Agent** --- #### 简单应用：如何修复一个 json 串？ ----- - 错误做法： - 问大模型这个字符串哪里错了？ - 写代码修复字符串 - 正确做法： - "Do not change the specific content, fix the json, directly return the repaired JSON, without any explanation and dialogue." --- #### 什么情况下我们需要 Agent ？ ----- - 不需要的情况： - 操作简单，人可以快速解决； - 规则清晰，程序可以按规则解决； - 需要的情况： - 解决步骤繁琐，对于人来说是重复劳动； - 情况复杂，不容易梳理清楚对应的解决规则； --- #### 场景举例 ----- - Github 的 Copilot - MacOS 的 Copilot - 软件自动运维 - Yi 6B 的自动安装助手 - 上网助手 - $\dots$ --- #### 高级场景举例 ----- - 自动软件开发（GPT Engineer） - 自动会议纪要 - 自动任务记录 - 自动会议预定 - 自动消息通知 - 高级个人助理 - 一切自动化流程中需要人工参与的部分 --- #### 解决复杂问题有哪些难点？ ----- - 解决复杂问题往往需要很多步骤； - 而且正确的步骤往往也也需要探索； - Agent 需要能够正确的了解自己当前解决问题的进度； - 具体的步骤中，Agent 需要可以使用具体的工具； --- #### 传统 Agent 的定义 ###### **Agent = LLM + planning + memory + tools** ----- &lt;center>&lt;img src="https://s2.loli.net/2023/12/18/Pucaj8OELXfeTZm.jpg">&lt;/center> --- ### Agent 究竟是如何工作的？ --- #### ReAct：Agent 的核心模式 &lt;center>&lt;img src="https://s2.loli.net/2023/12/18/klDFI9n2Mq5Kf61.png" width="70%">&lt;/center> --- #### ReAct 的核心思想 ----- - 循环试错（以此来取消幻觉）； - 充分利用大模型的能力（复杂条件下也总能给出解决方案）； - 大模型的知识足够多，且有泛化性，适合解决复杂问题； - 大模型可以很好的理解复杂的条件，找出适合的解决方案； - 通过对历史行为的记录（记忆），避免重复错误的尝试； --- ### Agent 测验 --- #### 如何打造一个联网的 LLM ？ ----- - **[Thought]** 针对用户输入，让 LLM 判断应该从哪个`搜索引擎`用什么`关键词` 获取结果； - **[Act]** 获取`搜索引擎`在对应`关键词`下的搜索结果； - **[Obs]** 具体返回的搜索结果； - **[Thought]** 判断是否回答了用户的输入，如果没有，类似第一步，继续判断如何搜索； --- #### 如何打造 Yi 6B 的自动安装助手 --- #### 如何打造 MacOS 的 Copilot --- #### 如何打造一个可以自动软件开发的 Agent --- ### 这件事需要产品做什么？ --- - **找到适合的场景** - 设计场景下的合理交互 - 总结场景下的最佳实践(作为数据喂给模型就可以了) - 扩展场景 --- > 大模型还没有出现 Killer APP 是因为还没有懂 Agent 的产品经理 --- # Q & A</p></div><footer class=entry-footer><span title='2023-12-10 09:55:03 +0800 CST'>2023-12-10</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to Agent 使用指南" href=https://blog.uglyboy.cn/slides/2023/12/10/agent-%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>RAG 技术</h2></header><div class=entry-content><p># RAG 技术 --- - 检索增强的生成系统（Retrieve Augment Generation）简称 RAG。 - 原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得与用户问题相关的更多上下文信息，使得的大语言模型可以： - 降低幻觉出现概率 - 适应垂直场景应用 - 弥补数据实时性不足 --- ### 一个典型 RAG 系统的架构 &lt;center>&lt;img src="https://oss.uglyboy.cn/image/2024/11/30e352cefa60c93ac742a0aee2d81cf7.jpg">&lt;/center> --- ### RAG 系统的核心技术要素 - 文档导入 - 文档切分 - 文档向量化 - 向量数据库选型 - 检索算法 - 文档排序 - Prompt 生成 - $\dots$ --- 市面上大部分的关于 RAG 的介绍都是类似上面的逻辑进行的，然后就顺利的将 *某一种 RAG 的方法* 变成了 *通用 RAG 的框架*，从而让我们迷失了 RAG 的真正价值。 --- ## 从定义出发，RAG 就是 ## 检索 + 生成 --- - Chat With Documents 属于 RAG - 用户对话中保留历史记忆 属于 RAG - 网页搜索 + LLM 属于 RAG - 自动调用 API 接口获取信息 属于 RAG - 调用数据库获取信息 属于 RAG - $\dots$ - **上面各种方法一起使用也属于 RAG** --- ## RAG 究竟意味着什么？ > 为什么我们要使用检索 --- - 人类行为的两种模式：主动获取信息（功利动机行为）和被动获取信息（共情动机行为）； - 通常在产品上，我们可以用 *Save time* 和 *Kill time* 的模式来区分 - 主动获取信息的手段被称为信息检索。 - RAG 更标准的说法应当是有了 LLM 能力加持的信息检索。 --- ## LLM 很难独立完成检索 --- - 最核心的问题是，对于如何引导大模型按照我们的意愿生成内容，**我们无法直接控制，我们只能通过增加上下文的方式来影响生成结果**。 - 对于大模型来说，它会如何回答一个问题依赖的不是训练框架，而是训练数据。 - 我们无法直接控制大模型的生成结果，但是我们可以通过增加上下文的方式来影响生成结果。 - 一个问题，我们可以提供相关的上下文，然后利用大模型的泛化能力，让它生成我们想要的答案。 --- &lt;center>&lt;img src="https://oss.uglyboy.cn/image/2024/11/4257471c0658350b4ddf3ec478c1a96c.png">&lt;/center> --- - 大模型的“记忆力”并不可靠，不同的上下文会引导出怎样的结果是不确定的。 - 仅靠大模型，是无法取消幻觉的。 - 如果 RAG 做得不好，可能带来的是负面效果。 --- ## RAG 的核心 ## 如何用好检索 --- ## 检索的发展史 1. 图书馆的索引式检索（Yahoo 等目录网页）； 2. 关键词召回（传统搜索）； 3. 向量相似度（个性化推荐）； 4. 自然语言回答问题（大模型）； > 这些方法不是递进的，而是并列的。 --- ## 新概念下的 RAG 框架 --- 1. 对用户问题分类，判断使用哪些检索器； 2. 根据用户问题，找到最适合的检索器检索方式（Query、SQL、API 调用等）； 3. 召回的结果，判断与用户问题的相关性，进行合理过滤或改进； 4. 用适合的方式组织召回结果，提供给 LLM 进行汇总并回答用户问题； 5. （可选）判断是否很好的回答了用户的问题，是否需要重新再来一遍（这其实就进化成 Agent 了）。 --- - 可以使用不同的 LLM 来执行不同的任务，这样就可以在计算速度和资源上得到极大的节约，并针对特定问题取得更好的效果。 - 检索器的各种优化技术都值得使用： - 包括传统的关键词搜索（QP） - 向量检索只是其中的一种手段；同时向量检索也应当额外建立适合的索引。 - 知识图谱是有效的检索器之一。 - 利用好结构化信息（数据库 或 API）。 - 好的检索器依赖好的数据。 --- # Q & A --- #### 如果我们有一些私有的数据，如何让大模型能够利用这些私有数据呢？ ----- - 通过微调的方式，将私有数据加入到大模型的训练数据中。 - 通过检索的方式，将私有数据加入到大模型的上下文中。 - **以上方法都用** --- #### 怎样才能更好的提升 RAG 的效果？ ----- 最核心的要素其实是：找到更优质的数据（准确、结构化） --- #### 产品和开发要深入研究 Prompt Engineering 吗？ ----- 永远都不要这样做，这件事交给 SFT - 概念对比 - Let’s think step by step - 通用优化 Prompt 的 Prompt - function call - Self RAG - 让模型来学习如何 Prompt Engineering</p></div><footer class=entry-footer><span title='2023-11-23 06:35:17 +0800 CST'>2023-11-23</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to RAG 技术" href=https://blog.uglyboy.cn/slides/2023/11/23/rag-%E6%8A%80%E6%9C%AF/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>大模型的计算能力</h2></header><div class=entry-content><p>## 大语言模型的计算能力 --- ### LLM 的几个核心数学问题 ----- 1. N-GRAM 的计算能力问题 2. 过参数化模型的统计学习问题 3. 非凸的数值优化问题 4. 对深度神经网络的数学理解 5. Transformer 算子的含义 6. fine-tuning 的数学含义 --- ### N-GRAM 的计算能力 --- - **大语言模型的基本范式：** - 假设 $w_1, w_2,\dots, w_{N}$ 是一个单词序列。我们可以按如下公式计算单词序列的概率： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ - 该模型是一个 $N-1$ 阶的马尔可夫链，称为 `N-GRAM` 模型。 - 该模型的计算能力是有限的，因为它的是个有穷自动机。 --- - `非确定型有穷自动机`(`NFA`) 是一个 5 元数组 $Q,\Sigma,\delta,q_0,F$，其中 - $Q$ 是一个有穷集合，称为**状态集**。 - $\Sigma$ 是一个有穷集合，称为**字母表**。 - $\delta:Q\times\Sigma_\varepsilon\rightarrow \mathcal{P}(Q)$ 是**转移函数**。 - $q_0\in Q$ 是**起始状态**。 - $F \subseteq Q$ 是**接受状态集**。 --- #### 大模型是有穷自动机的证明过程 ----- - 令 $q_0 =\varepsilon$ 为初始状态，大语言模型的预测函数记为 $$ \phi:\{s_0s_1s_2...s_{n-1}\}\rightarrow s_n,s_i \in \Sigma $$ - 取 $\delta$ 为： $$ \begin{equation} \delta(q,\sigma) = \left \\\{ \begin{array}{ll} q \circ\sigma & \sigma \neq \varepsilon\\\\ q \circ\phi(q) & \sigma = \varepsilon \end{array} \right. \end{equation} $$ - 也就是将 $Q$ 设置为已经拥有的上文，持续输入或预测下一个字符。 --- - 在 [Bhattamishra et al. 2020](https://arxiv.org/abs/2009.11264) 中也有类似的实验，实验中基于 Transformer 的大语言模型甚至只能识别弱化的正则语言。 - 大模型无法判别一个 $\{[0|1]^*\}$ 序列中是否有奇数个 $1$。 - 给定 $n$ 大模型无法生成 $(aa)^n$。 - 在 [Zhou et al. 2023](http://arxiv.org/abs/2310.16028) 中还尝试论述了基于 Transformer 的大语言模型也无法实现加法运算之类的复杂运算。 - 以及，有穷自动机无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列；也无法进行基础的四则运算（无法处理括号的闭合和乘法的优先顺序）。 --- ### 大模型计算能力是有限的 ----- - 大模型不具备推理能力，这件事与模型的规模无关。 - 大模型是通过语言概率分布的泛化来模拟出推理能力的假象。 - 例如：大模型不会数数。他只是把看到过的数数类型的答案都记住了，然后用类比的方式去回答新的问题；如果答案在记忆中，就会回答正确。 - 更大的模型可以记住更多的答案，但是这并不是我们想要的答案。 - 我们需要新的范式来解决 AGI 问题。 --- ### Agent + LLM 可以成为完备图灵机 --- - Agent 的基本范式是一个 While 程序。 - 例如下面几种常见的 Agent： 1. [ReAct](http://arxiv.org/abs/2210.03629) 获得反思推理能力 2. [BabyAGI](https://github.com/yoheinakajima/babyagi) 基础的计划任务 Agent 3. [Reflexion](http://arxiv.org/abs/2303.11366) 长期记忆和短期记忆（短期记忆就符合上述流程） 4. [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) 第一个全能 Agent --- - 代码示例： ```python @dataclass class ReAct(ABC): thought: Optional[str] = None action: Optional[str] = None def __post_init__(self): self.obs = self.run() # 获取执行 Action 的结果 act = ReAct() acts = [] while not act.done: acts.append(act) prompt = get_prompt(acts) act: ReAct = ReAct.parse(llm.call(prompt)) # 调用大模型 ``` --- #### 编程语言 WHILE 语义 (Semnatik) ----- - 一个 while 程序 $P$ ,通过传递 $k$ 个参数,返回一个结果, 即 $f:\mathbb{N}^k\rightarrow\mathbb{N}$ - 其他未定义的参数可以在程序里被调用,但是必须设定为 $0$ - WHILE 程序的结果在结束结束后通过 $x_0$ 传达 - 对于一个 WHILE 程序,有三种运行模式: - 变量赋值: $x_i=x_j+c,c\in\{0,1,−1\}$ - $P_1$;$P_2$ ( $P_1$,$P_2$ 是两个任意程序程序),先运行 $P_1$ ,再运行 $P_2$ - WHILE $x_i \neq 0$ DO $P$ END 意思是, $P$ 程序将一直被运行,直到 $x_i$ 等于 0 --- - **定理：编程语言 WHILE 是图灵完备的** - **证明:** 我们将受限 RAM(Registermaschine)(只有 LOAD,STORE,CLOAD,CADD,CSUB 功能的 RAM) 中的每一步都用 WHILE 程序来代替计算，由于受限 RAM 是图灵完备的,所以 WHILE 也是图灵完备的。 - 证明细节参看：[while循环](https://zhuanlan.zhihu.com/p/343107128) ，源自 [Unentscheidbarkeit des Halteproblems: WHILE-Programm, Vorlesung 10 in BUK von RWTH Aachen](https://algo.rwth-aachen.de/Lehre/WS1920/BuK/BuK/h10.pdf) --- - 实现图灵完备的方法不是唯一的。例如，[Schuurmans 2023](http://arxiv.org/abs/2301.04589) 就证明了，当可以使用外部存储时，大模型是图灵完备的。 - 但是，这并不意味着 Agent + LLM 就是 AGI，毕竟我们现在的电脑本身就是图灵完备的，但是我们并不认为电脑就是 AGI。 - 我们需要的是一个可以自适应的 Agent，而不是一个固定的 Agent。也就是可以通过学习来改变自己的行为，而不是通过人工的方式来改变自己的行为。 --- ### 以整数加法为例 ----- > 我们希望 Agent 学会整数加法。但学会的方式不是我们给了它加法的程序让它执行，而是通过加法的真值，“推导”出加法的程序。模拟人做加法的方式，我们尝试让机器训练出加法程序 --- - **已知**： - 十以内的加减法（这部分的结果是背下来的）； - 用字符串来保存十进制的数字； - 有额外的存储可以利用（保存进位时的信息）； - **目标：** - 懂得如何利用已知的十以内的加减法的结果，进行多位的加减法运算； - 计算时需要从后向前计算； - 需要保留进位的信息； - 确保计算结果一定是准确的； --- - 这应该是一个强化学习的过程——只有计算正确时，才会获得奖励。其中，尝试探索的动作空间是： - 如何利用十以内的加减 - 通过怎样的计算顺序 - 如何利用额外的存储 - 最终以此来生成一个完整的加法运算流程。 --- ### 使用 RL 训练 Agent ----- Agent 的 While 循环模式恰好符合 Bellman 方程的形式。 --- > 通过强化学习训练 Agent，直观上，状态空间和奖励都不难定义，难的是究竟如何定义 Action 空间。 --- - 例如十以内的加减法为什么可以成为加法的 Action？ - 进一步，当我们尝试训练乘法时，九九乘法表一定在我们的 Action 空间中，那如何凭空让机器找到这个“九九乘法表”呢？ - 甚至计算乘法时，加法也需要在 Action 空间中。这意味着，强化学习能学会内容是有序的，而且 Action 空间的生成也是依赖之前的训练结果的。 - 这个结果并不意外，《技术的本质》一书中就提到过人类技术的发展是渐进的，而不是突变的。 --- > 牛顿无法简单的通过阅读代数和几何来发明微积分。问题是，要生成全新的想法，还缺什么？ **有可能达成 AGI 的新范式应当需要 Agent + LLM 的联合训练，而不是各自的单独训练。** --- ## Thanks</p></div><footer class=entry-footer><span title='2023-11-21 01:45:37 +0800 CST'>2023-11-21</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 大模型的计算能力" href=https://blog.uglyboy.cn/slides/2023/11/21/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%A1%E7%AE%97%E8%83%BD%E5%8A%9B/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>大语言模型原理分享</h2></header><div class=entry-content><p># 大语言模型&lt;br>原理分享 --- ## 什么是大语言模型？ --- 当我说了很多话之后，我马上要说 $\Box$ --- ## 数学公式描述 ----- $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ --- ## 大语言模型能做什么？ --- - 大模型能记住它看到过的一切信息。 - 大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。 --- ### 大模型能达到怎样的泛化能力？ > 大模型可以涌现出智能吗？ --- ## 大语言模型不能做什么？ --- 1. 大模型无法判别一个 $\\\{[0|1]^*\\\}$ 序列中是否有奇数个 $1$。 2. 给定 $n$ 大模型无法生成 $(aa)^n$。 3. 大模型无法判定 $\\\{0^n\\\#1^n\\\}$ 形式的序列。 4. 大模型无法执行加法运算。 5. $\dots$ --- 大语言模型没有，也不可能具有推理能力。 > 大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。 --- ## 大语言模型是如何将信息泛化的？ --- - 通过相似度计算来进行泛化，然后通过概率分布来进行选择。 1. 粗略的可以如下理解：可以用同义词替代的都能被泛化。 2. 这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。 3. 在训练样本充分的情况下，可以跨语言进行同义词泛化。 --- # Q & A</p></div><footer class=entry-footer><span title='2023-11-21 01:45:37 +0800 CST'>2023-11-21</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 大语言模型原理分享" href=https://blog.uglyboy.cn/slides/2023/11/21/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%88%86%E4%BA%AB/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>组织理论讲义</h2></header><div class=entry-content><p># 组织理论 > 组织背后的核心要素 --- - 员工没有主人翁意识，工作不积极，不加班； - 不同部门不能很好的协同合作，总是互相指责，甚至拆台； - 大家想法不统一，总也拧不成一股绳； - 团队氛围不好，大家都是精致的利己主义者； - 留不住好员工，优秀的人培养一阵子就要跳槽（创业）去了； --- #### 有哪些手段可以解决这些组织问题？ ----- - 提升管理能力（领导能力、战略决策能力等） - 调整组织架构、流程、制度（机制设计、利益分配） - 优化战略目标的设定和拆解（KPI 考核） - 组织文化建设（使命、愿景、价值观） --- #### 可这些“办法”总让人有些隔靴瘙痒 ----- - 各种方案分属不同的领域，为何能解决同一类问题？ - 这些问题好像也没办法被解决，只能被改进； - 难以定义一个组织“质量”指标，来衡量这些手段带来的改进程度 --- ### 组织的本质是共情 组织是一群有共情的人尝试进一步获取共情信息的团体 --- #### 考察一下这些组织 ----- - 定期逛街的闺蜜、一起网吧开黑的同学； - 孩子们的小团体； - 帮派、社团、集会、论坛、粉丝群； - 宗教、党派、学术圈； - 旅行团、学校、企业； --- ## 构建一个好组织 > 组织究竟是什么？ --- #### 如何构建好一个社群（BBS） ----- - 社群是解决共情需求的： - 找到一个社群的核心共情话题，吸引对之感兴趣的人来； - 鼓励大家多针对核心话题讨论聊天，提升共情的频次； - 设立版主，把更有共情感的话题置顶，同时删除无关话题； - 拉来更资深的内容创作者，提升核心话题的共情程度； --- #### 如何构建好一个社团 ----- - 社团是线下实体组织，在信息的传播上，比线上（社群）可控但效率低： - 社团一定要定期（高频）组织活动，在活动中也要尽量提升共情的频率；社团线下活动之余，还可以通过线上渠道提升共情频率； - 在社团成员间，可以通过形成非社团主题的共情，提升社团整体共情； - 社团好不好，看社团的组织能力；社团的组织能力，看社长的影响力； --- #### 如何构建好一个企业 ----- - 好的企业应当也是一个好的社团： - 公司的共情主题是什么？（使命愿景价值观） - 老板是不是企业中这个共情主题的 KOL？（领导力来源于认同） - 企业中做了哪些增加共情主题的工作吗？（企业文化） - 企业中非主题的员工共情多吗？（公司氛围） - *好公司的评判标准：员工能否感受到企业中的共情（非物质），进而感到很快乐？* --- #### 如何构建一个好的国家 ----- - 国家的共情是什么？ - 统一编码、内容、观点； - 怎样成为一个好的国家领导人？ - 领导人需要是国家共情的 KOL； - 经济未必能成就一个国家（晚清），或灭亡一个国家（新中国）；但文化可以。 --- #### 组织的“质量” ----- - 组织的本质是共情，组织“质量”的评估标准是组织（作为信息提供者）带来共情的能力： - 共情信息的频率； - 共情信息的共情程度； - 组织具有群体性，所以一定会存在 KOL： - KOL 才是组织实质的领导者； - KOL 给组织成员提供的共情水平决定了组织的下限； --- ## 组织实战检验 > 根据理论，开始实操 --- #### 作为一个组织的领导（企业 CEO），最重要的使命是什么？怎么检验？ --- #### 团队协同出问题/团队氛围不好/组织成员没有积极性，这是谁的责任？用什么办法调整（是否方法不当）？ --- - 考察一下自己团队的组织共情建设： - 核心组织共情（编码、共情、观点）有哪些？ - 共情频率如何？有什么组织保障？ - 对新员工（低共情员工）有哪些共情培养方式？ - 对有利/不利于共情的声音的处理方式？ --- ## 看几个案例 > 组织问题不再扑朔迷离 --- #### 组织成员贡献的意愿 ----- - 员工为什么愿意加班？为什么应当有主人翁意识？为什么工作中要有更强的主动性？ - 所谓工作态度的问题，可以归结成：组织成员有多强的贡献的意愿： - 贡献的意愿，意味着不满足功利动机（功利动机下不会贡献的）； - 获得足够的共情反馈，才能鼓励一个人用贡献的行为来获取更多的共情信息；另一方面，共情动机才促使一个人改变自己； - 回归到具体的人，共情之间没有本质的区别，可以是集体荣誉感，可以是事业感使命感，也可以只是职业精神，甚至“士为知己者死”； --- #### 成员间的信任和协同 ----- - 成员间的信任和协同，依赖的不过是成员间的共情程度； - 组织架构的调整，本质上调整的是小组织的范围，形成小团体的组织共情，以提升特定成员间的共情程度； - 开会、团建、轮岗、“联姻”等等方法都可以提升相关成员间的共情程度； - 组织中整体的组织共情越强，成员间的组织共情就越强； - 相互补位是很难依靠制度来保障的。因为补位的发生，往往意味着未预期的状况，这种状况大概率是没办法事前约定或被熟练执行的。 --- #### 老兵不死，只是凋零 ----- - 谁是最有组织共情，最能维护组织共情，最能贡献共情内容的人？在组织中呆的更久的人； - 组织未来的 KOL 也应当从组织中诞生； - 绩效考核已经衡量了老兵的功利价值，但允许老兵终老，在组织中贡献更多的共情价值吧，这种价值是钱买不到的 --- #### 不要用法律的方式对待道德 ----- - 形成共情的方式是给予可共情的信息，而不是功利的奖惩； - 用法律的方式对待道德，注定解决不了根本问题——共情是近期信息共情的均值，而不是某条信息的共情合格率； - 通过 KPI 考核组织成员，永远没办法提升组织共情，甚至会更加糟糕。 - 阿里的月饼事件就是一个典型的管理手段在共情方面的滥用，带来了长期的不良影响。 --- #### 从宗教看组织管理 - 从宗教组织中的现象来看： - 宗教信徒都有强烈贡献的意愿； - 宗教信徒间往往可以有很好的互信； - 宗教建立的是一种高频度高质量的共情渠道： - 定期做宗教信息（共情信息）的交流； - 在编码、内容、观点上都会形成极高的共情密度；</p></div><footer class=entry-footer><span title='2022-10-15 20:20:25 +0800 CST'>2022-10-15</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 组织理论讲义" href=https://blog.uglyboy.cn/slides/2022/10/15/%E7%BB%84%E7%BB%87%E7%90%86%E8%AE%BA%E8%AE%B2%E4%B9%89/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>科学决策讲义</h2></header><div class=entry-content><p># 科学决策 > 如何做出正确的决策 --- #### 什么是决策 ----- - 想做的事情很多，但没有足够的资源全做，所以要进行优先级排序； - 决策的基本原则： - 找到主要矛盾，对方案做优先级排序； - 当主要矛盾退化为次要矛盾时，重新针对新的主要矛盾重复上述过程； --- - 北京簋街（著名的美食街）有一家麻辣小龙虾的店：通乐老店，经营多年，营收情况一直比较稳定（盈利）。请问它如果有 500w 的投资，想进一步的发展，你会采取怎样的策略？ - 研究特色小龙虾； - 开发小龙虾以外的特色美食； - 在簋街开分店（或扩大店面）； - 在簋街之外开分店； - 以上都做尝试； --- - 簋街的特色是麻辣小龙虾，绝大部分食客就是冲着麻辣小龙虾去的簋街； - 簋街最大的小龙虾品牌是胡大和仔仔，都有至少 5～6 家分店，而且每家分店在高峰期都会排很长的队； - 通乐老店的大众点评中高赞评价是：味道不错；相比于胡大和仔仔，最大的好处是不用排队，上菜快，停车方便； - 大众点评的高赞菜，除麻辣小龙虾外，主要是：麻辣板筋、馋嘴蛙、麻辣蜗牛等麻辣的特色料理。 --- #### 还有一些信息 ----- - 小龙虾具有季节性； - 簋街的地租明显高于簋街外临近区域的租金； - 预制菜和直播（吃播）是当下年轻人中流行的方式； - 簋街有一家“很久以前羊肉串”也非常的火，每天排队的人也很多； --- #### 启示 ----- - 决策需要充分且必要的信息。 - 决策是一门科学： - 不同的决策者能够根据具体情况（信息充分时），得出相同或相似的结论。 - 如果出现不同的决策，首先要看信息是否对齐且充分和必要，再看是否运用了科学的态度进行决策。 --- ## 决策所需要的信息 > 市场和份额 --- #### 市场视角的演进 ----- ```mermaid flowchart LR A[产品视角] B[客户视角] C[竞争视角] D[市场视角] A --> B B --> C C --> D ``` --- ### 定义市场 ----- 市场刻画了客户视角 --- #### 顾客的需求定义了市场 ----- - 特定需求（顾客）的可替代性产品（生产者）的集合，构成一个市场 - 市场不是随意定义出来的，是由（顾客的）需求确定的； - 一个市场中的可替代性产品之间都是竞争关系； - 一个产品可以同时处于多个市场当中； --- #### 错误决策的常见原因一：错判了市场 ----- - “无代码”是否是一个市场？ - 商汤、旷世所在的“人工智能赛道”处在什么市场中？ - 索引科技处于什么市场中？主要的竞争对手究竟是谁？ --- ### 市场份额 ----- 市场份额刻画了产品和竞争视角 --- #### 用市场份额衡量产品能力 ----- - 自身的全部产品能力都体现在当前的市场份额中； - 竞争对手的产品能力也类似，都体现在他们的市场份额中； - 业务方向的决策，要根据与最大的竞争对手（很容易从市场份额中得到判断）之间的优势和劣势，做出选择； - 基于自身不同的市场份额，得到的决策也不同。 --- #### 错误决策的常见原因二：不从份额看问题 ----- - 阿里一个项目能进“双十一”，就能拿到好的数据结果，能说明什么问题？ - 业务增长不如大盘，其实就意味着落后于竞争者了。 - 有正向收益不能证明事情做对了，收益负向也不能说明事情做错了，需要从份额的视角看问题。 --- ## 科学决策 > 相投投入，如何获得更大的市场份额 --- #### 业务方向的科学决策 ----- - 业务方向的选择，是在各种优势和劣势中做出判断——优先发展哪一项优势，或优先补足哪一项劣势； - 在竞争环境中，会更容易做出业务方向的判断（两点确定直线）： - 有特定的竞争对手，容易在对比中找到主要优势和劣势； - 决策是做判断：巩固主要优势还是补足明显劣势； --- #### 错误决策的常见原因三：不看比较优势做决策 ----- - “同样的资源，为什么要给到你？” - 不是有价值的项目就值得做： - 要看投入产出比，而不只是产出； - 需要将所有有价值的项目进行优先级排序，进而决策优先做什么； --- #### 错误决策的常见原因四：无视定位做决策 ----- - 海底捞和巴奴毛肚火锅，战略打法一定是不同的； - 大企业的经验在初创企业中不适用；初创企业的经验同样也带不到大企业当 中： - 企业不同的阶段，市场定位不同，科学的决策自然也不同； - 凭手感做决策，你的经验可能跟当前发展阶段不匹配； --- ## 商战 > 基本竞争策略 --- #### 基本竞争策略 ----- - 市场领先者的策略： - 以自己为假想敌，攻击自己； - 针对追赶者的策略，做防御（follow 对手的策略）； - 追赶者的策略： - 在领先者的优势中找弱势，作为主攻方向； - 小角色（无法与对手进行相同投入的竞争）的策略： - 避开大家伙，聚焦小市场，获得相同投入下的优势； --- ### 错误的决策 ----- 导致我们做出错误决策的常见原因 --- #### 常见原因 ----- 1. 错判了市场； 2. 不从份额看问题； 3. 不看比较优势做决策； 4. 无视定位做决策；</p></div><footer class=entry-footer><span title='2022-04-27 17:26:35 +0800 CST'>2022-04-27</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;癸老师</footer><a class=entry-link aria-label="post link to 科学决策讲义" href=https://blog.uglyboy.cn/slides/2022/04/27/%E7%A7%91%E5%AD%A6%E5%86%B3%E7%AD%96%E8%AE%B2%E4%B9%89/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://blog.uglyboy.cn/slides/page/2/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=https://blog.uglyboy.cn/>拾柒读库</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>