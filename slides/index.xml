<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>演示 on 拾柒读库</title>
    <link>https://blog.uglyboy.cn/slides/</link>
    <description>Recent content in 演示 on 拾柒读库</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language><atom:link href="https://blog.uglyboy.cn/slides/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG 技术</title>
      <link>https://blog.uglyboy.cn/slides/2.-rag%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Thu, 23 Nov 2023 06:35:17 +0800</pubDate>
      
      <guid>https://blog.uglyboy.cn/slides/2.-rag%E6%8A%80%E6%9C%AF/</guid>
      <description>RAG 技术 检索增强的生成系统（Retrieve Augment Generation）简称 RAG。 原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得</description>
      <content:encoded><![CDATA[<h1 id="rag-技术">RAG 技术</h1>
<hr>
<ul>
<li>检索增强的生成系统（Retrieve Augment Generation）简称 RAG。</li>
<li>原理是在大语言模型的基础上，辅助检索技术，让大语言模型能够获得与用户问题相关的更多上下文信息，使得的大语言模型可以：
<ul>
<li>降低幻觉出现概率</li>
<li>适应垂直场景应用</li>
<li>弥补数据实时性不足</li>
</ul>
</li>
</ul>
<hr>
<h3 id="一个典型-rag-系统的架构">一个典型 RAG 系统的架构</h3>
<!-- raw HTML omitted -->
<hr>
<h3 id="rag-系统的核心技术要素">RAG 系统的核心技术要素：</h3>
<ul>
<li>文档导入</li>
<li>文档切分</li>
<li>文档向量化</li>
<li>向量数据库选型</li>
<li>检索算法</li>
<li>文档排序</li>
<li>Prompt 生成</li>
<li>$\dots$</li>
</ul>
<hr>
<p>市面上大部分的关于 RAG 的介绍都是类似上面的逻辑进行的，然后就顺利的将 <code>某一种 RAG 的方法</code> 变成了 <code>通用 RAG 的框架</code>，从而让我们迷失了 RAG 的真正价值。</p>
<hr>
<h2 id="从定义出发rag-就是">从定义出发，RAG 就是</h2>
<h2 id="检索--生成">检索 + 生成</h2>
<hr>
<ul>
<li>Chat With Documents 属于 RAG</li>
<li>用户对话中保留历史记忆 属于 RAG</li>
<li>网页搜索 + LLM 属于 RAG</li>
<li>自动调用 API 接口获取信息 属于 RAG</li>
<li>调用数据库获取信息 属于 RAG</li>
<li>$\dots$</li>
<li><strong>上面各种方法一起使用也属于 RAG</strong></li>
</ul>
<hr>
<h2 id="rag-究竟意味着什么">RAG 究竟意味着什么？</h2>
<blockquote>
<p>为什么我们要使用检索</p>
</blockquote>
<hr>
<ul>
<li>
<p>人类行为的两种模式：主动获取信息（功利动机行为）和被动获取信息（共情动机行为）；</p>
<ul>
<li>通常在产品上，我们可以用 <code>Save time</code> 和 <code>Kill time</code> 的模式来区分</li>
</ul>
</li>
<li>
<p>主动获取信息的手段被称为信息检索。</p>
<ul>
<li>RAG 更标准的说法应当是有了 LLM 能力加持的信息检索。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="llm-很难独立完成检索">LLM 很难独立完成检索</h2>
<hr>
<ul>
<li>最核心的问题是，对于如何引导大模型按照我们的意愿生成内容，<strong>我们无法直接控制，我们只能通过增加上下文的方式来影响生成结果</strong>。
<ul>
<li>对于大模型来说，它会如何回答一个问题依赖的不是训练框架，而是训练数据。</li>
<li>我们无法直接控制大模型的生成结果，但是我们可以通过增加上下文的方式来影响生成结果。</li>
<li>一个问题，我们可以提供相关的上下文，然后利用大模型的泛化能力，让它生成我们想要的答案。</li>
</ul>
</li>
</ul>
<hr>
<!-- raw HTML omitted -->
<ul>
<li>
<p>大模型的“记忆力”并不可靠，不同的上下文会引导出怎样的结果是不确定的。</p>
<ul>
<li>仅靠大模型，是无法取消幻觉的。</li>
</ul>
</li>
<li>
<p>如果 RAG 做得不好，可能带来的是负面效果。</p>
</li>
</ul>
<hr>
<h2 id="rag-的核心">RAG 的核心</h2>
<h2 id="如何用好检索">如何用好检索</h2>
<hr>
<h2 id="检索的发展史">检索的发展史</h2>
<ol>
<li>图书馆的索引式检索（Yahoo 等目录网页）；</li>
<li>关键词召回（传统搜索）；</li>
<li>向量相似度（个性化推荐）；</li>
<li>自然语言回答问题（大模型）；</li>
</ol>
<blockquote>
<p>这些方法不是递进的，而是并列的。</p>
</blockquote>
<hr>
<h2 id="新概念下的-rag-框架">新概念下的 RAG 框架</h2>
<hr>
<ol>
<li>对用户问题分类，判断使用哪些检索器；</li>
<li>根据用户问题，找到最适合的检索器检索方式（Query、SQL、API 调用等）；</li>
<li>召回的结果，判断与用户问题的相关性，进行合理过滤或改进；</li>
<li>用适合的方式组织召回结果，提供给 LLM 进行汇总并回答用户问题；</li>
<li>（可选）判断是否很好的回答了用户的问题，是否需要重新再来一遍（这其实就进化成 Agent 了）。</li>
</ol>
<hr>
<ul>
<li>可以使用不同的 LLM 来执行不同的任务，这样就可以在计算速度和资源上得到极大的节约，并针对特定问题取得更好的效果。</li>
<li>检索器的各种优化技术都值得使用：
<ul>
<li>包括传统的关键词搜索（QP）</li>
<li>向量检索只是其中的一种手段；同时向量检索也应当额外建立适合的索引。</li>
<li>知识图谱是有效的检索器之一。</li>
<li>利用好结构化信息（数据库 或 API）。</li>
</ul>
</li>
<li>好的检索器依赖好的数据。</li>
</ul>
<hr>
<h1 id="q--a">Q &amp; A</h1>
<hr>
<h4 id="如果我们有一些私有的数据如何让大模型能够利用这些私有数据呢">如果我们有一些私有的数据，如何让大模型能够利用这些私有数据呢？</h4>
<hr>
<ul>
<li>通过微调的方式，将私有数据加入到大模型的训练数据中。</li>
<li>通过检索的方式，将私有数据加入到大模型的上下文中。</li>
<li><strong>以上方法都用</strong></li>
</ul>
<hr>
<h4 id="怎样才能更好的提升-rag-的效果">怎样才能更好的提升 RAG 的效果？</h4>
<hr>
<p>最核心的要素其实是：找到更优质的数据（准确、结构化）</p>
<hr>
<h4 id="产品和开发要深入研究-prompt-engineering-吗">产品和开发要深入研究 Prompt Engineering 吗？</h4>
<hr>
<p>永远都不要这样做，这件事交给 SFT</p>
<ul>
<li>概念对比</li>
<li>Let’s think step by step</li>
<li>通用优化 Prompt 的 Prompt</li>
<li>function call</li>
<li>Self RAG</li>
<li>让模型来学习如何 Prompt Engineering</li>
</ul>
]]></content:encoded>
    </item>
    
    <item>
      <title>大模型的计算能力</title>
      <link>https://blog.uglyboy.cn/slides/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%A1%E7%AE%97%E8%83%BD%E5%8A%9B/</link>
      <pubDate>Tue, 21 Nov 2023 01:45:37 +0800</pubDate>
      
      <guid>https://blog.uglyboy.cn/slides/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%A1%E7%AE%97%E8%83%BD%E5%8A%9B/</guid>
      <description>大语言模型的计算能力 LLM 的几个核心数学问题 N-GRAM 的计算能力问题 过参数化模型的统计学习问题 非凸的数值优化问题 对深度神经网络的数学理解 Transformer 算子的含义 fine-tuning 的</description>
      <content:encoded><![CDATA[<h2 id="大语言模型的计算能力">大语言模型的计算能力</h2>
<hr>
<h3 id="llm-的几个核心数学问题">LLM 的几个核心数学问题</h3>
<hr>
<ol>
<li>N-GRAM 的计算能力问题</li>
<li>过参数化模型的统计学习问题</li>
<li>非凸的数值优化问题</li>
<li>对深度神经网络的数学理解</li>
<li>Transformer 算子的含义</li>
<li>fine-tuning 的数学含义</li>
</ol>
<hr>
<h3 id="n-gram-的计算能力">N-GRAM 的计算能力</h3>
<hr>
<ul>
<li>
<p><strong>大语言模型的基本范式：</strong></p>
</li>
<li>
<p>假设 $w_1, w_2,\dots, w_{N}$ 是一个单词序列。我们可以按如下公式计算单词序列的概率：</p>
</li>
</ul>
<p>$$
p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i})
$$</p>
<ul>
<li>该模型是一个 $N-1$ 阶的马尔可夫链，称为 <code>N-GRAM</code> 模型。</li>
<li>该模型的计算能力是有限的，因为它的是个有穷自动机。</li>
</ul>
<hr>
<ul>
<li><code>非确定型有穷自动机</code>(<code>NFA</code>) 是一个 5 元数组 $Q,\Sigma,\delta,q_0,F$，其中
<ul>
<li>$Q$ 是一个有穷集合，称为<strong>状态集</strong>。</li>
<li>$\Sigma$ 是一个有穷集合，称为<strong>字母表</strong>。</li>
<li>$\delta:Q\times\Sigma_\varepsilon\rightarrow \mathcal{P}(Q)$ 是<strong>转移函数</strong>。</li>
<li>$q_0\in Q$ 是<strong>起始状态</strong>。</li>
<li>$F \subseteq Q$ 是<strong>接受状态集</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="大模型是有穷自动机的证明过程">大模型是有穷自动机的证明过程</h4>
<hr>
<ul>
<li>
<p>令 $q_0 =\varepsilon$ 为初始状态，大语言模型的预测函数记为
$$
\phi:{s_0s_1s_2&hellip;s_{n-1}}\rightarrow s_n,s_i \in \Sigma
$$</p>
</li>
<li>
<p>取 $\delta$ 为：
$$
\begin{equation}
\delta(q,\sigma) =
\left \{
\begin{array}{ll}
q \circ\sigma &amp; \sigma \neq \varepsilon\\
q \circ\phi(q) &amp; \sigma = \varepsilon
\end{array}
\right.
\end{equation}
$$</p>
</li>
<li>
<p>也就是将 $Q$ 设置为已经拥有的上文，持续输入或预测下一个字符。</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>在 <a href="https://arxiv.org/abs/2009.11264">Bhattamishra et al. 2020</a> 中也有类似的实验，实验中基于 Transformer 的大语言模型甚至只能识别弱化的正则语言。</p>
<ul>
<li>大模型无法判别一个 ${[0|1]^*}$ 序列中是否有奇数个 $1$。</li>
<li>给定 $n$ 大模型无法生成 $(aa)^n$。</li>
</ul>
</li>
<li>
<p>在 <a href="http://arxiv.org/abs/2310.16028">Zhou et al. 2023</a> 中还尝试论述了基于 Transformer 的大语言模型也无法实现加法运算之类的复杂运算。</p>
</li>
<li>
<p>以及，有穷自动机无法判定 $\{0^n\#1^n\}$ 形式的序列；也无法进行基础的四则运算（无法处理括号的闭合和乘法的优先顺序）。</p>
</li>
</ul>
<hr>
<h3 id="大模型计算能力是有限的">大模型计算能力是有限的</h3>
<hr>
<ul>
<li>大模型不具备推理能力，这件事与模型的规模无关。</li>
<li>大模型是通过语言概率分布的泛化来模拟出推理能力的假象。
<ul>
<li>例如：大模型不会数数。他只是把看到过的数数类型的答案都记住了，然后用类比的方式去回答新的问题；如果答案在记忆中，就会回答正确。</li>
<li>更大的模型可以记住更多的答案，但是这并不是我们想要的答案。</li>
</ul>
</li>
<li>我们需要新的范式来解决 AGI 问题。</li>
</ul>
<hr>
<h3 id="agent--llm-可以成为完备图灵机">Agent + LLM 可以成为完备图灵机</h3>
<hr>
<ul>
<li>Agent 的基本范式是一个 While 程序。</li>
<li>例如下面几种常见的 Agent：
<ol>
<li><a href="http://arxiv.org/abs/2210.03629">ReAct</a> 获得反思推理能力</li>
<li><a href="https://github.com/yoheinakajima/babyagi">BabyAGI</a> 基础的计划任务 Agent</li>
<li><a href="http://arxiv.org/abs/2303.11366">Reflexion</a> 长期记忆和短期记忆（短期记忆就符合上述流程）</li>
<li><a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a> 第一个全能 Agent</li>
</ol>
</li>
</ul>
<hr>
<ul>
<li>代码示例：</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nd">@dataclass</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ReAct</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">thought</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="n">action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">__post_init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">()</span> <span class="c1"># 获取执行 Action 的结果</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">act</span> <span class="o">=</span> <span class="n">ReAct</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">acts</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl"><span class="k">while</span> <span class="ow">not</span> <span class="n">act</span><span class="o">.</span><span class="n">done</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">acts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">act</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">prompt</span> <span class="o">=</span> <span class="n">get_prompt</span><span class="p">(</span><span class="n">acts</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">act</span><span class="p">:</span> <span class="n">ReAct</span> <span class="o">=</span> <span class="n">ReAct</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">llm</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">prompt</span><span class="p">))</span> <span class="c1"># 调用大模型</span>
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<h4 id="编程语言-while-语义-semnatik">编程语言 WHILE 语义 (Semnatik):</h4>
<hr>
<ul>
<li>一个 while 程序 $P$ ,通过传递 $k$ 个参数,返回一个结果, 即 $f:\mathbb{N}^k\rightarrow\mathbb{N}$</li>
<li>其他未定义的参数可以在程序里被调用,但是必须设定为 $0$</li>
<li>WHILE 程序的结果在结束结束后通过 $x_0$ 传达</li>
<li>对于一个 WHILE 程序,有三种运行模式:
<ul>
<li>变量赋值: $x_i=x_j+c,c\in{0,1,−1}$</li>
<li>$P_1$;$P_2$ ( $P_1$,$P_2$ 是两个任意程序程序),先运行 $P_1$ ,再运行 $P_2$</li>
<li>WHILE $x_i \neq 0$ DO $P$ END 意思是, $P$ 程序将一直被运行,直到 $x_i$ 等于 0</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>定理：编程语言 WHILE 是图灵完备的</strong></p>
</li>
<li>
<p><strong>证明:</strong> 我们将受限 RAM(Registermaschine)(只有 LOAD,STORE,CLOAD,CADD,CSUB 功能的 RAM) 中的每一步都用 WHILE 程序来代替计算，由于受限 RAM 是图灵完备的,所以 WHILE 也是图灵完备的。</p>
</li>
<li>
<p>证明细节参看：<a href="https://zhuanlan.zhihu.com/p/343107128">while循环</a> ，源自 <a href="https://algo.rwth-aachen.de/Lehre/WS1920/BuK/BuK/h10.pdf">Unentscheidbarkeit des Halteproblems: WHILE-Programm, Vorlesung 10 in BUK von RWTH Aachen</a></p>
</li>
</ul>
<hr>
<ul>
<li>
<p>实现图灵完备的方法不是唯一的。例如，<a href="http://arxiv.org/abs/2301.04589">Schuurmans 2023</a> 就证明了，当可以使用外部存储时，大模型是图灵完备的。</p>
</li>
<li>
<p>但是，这并不意味着 Agent + LLM 就是 AGI，毕竟我们现在的电脑本身就是图灵完备的，但是我们并不认为电脑就是 AGI。</p>
</li>
<li>
<p>我们需要的是一个可以自适应的 Agent，而不是一个固定的 Agent。也就是可以通过学习来改变自己的行为，而不是通过人工的方式来改变自己的行为。</p>
</li>
</ul>
<hr>
<h3 id="以整数加法为例">以整数加法为例</h3>
<hr>
<blockquote>
<p>我们希望 Agent 学会整数加法。但学会的方式不是我们给了它加法的程序让它执行，而是通过加法的真值，“推导”出加法的程序。模拟人做加法的方式，我们尝试让机器训练出加法程序</p>
</blockquote>
<hr>
<ul>
<li><strong>已知</strong>：
<ul>
<li>十以内的加减法（这部分的结果是背下来的）；</li>
<li>用字符串来保存十进制的数字；</li>
<li>有额外的存储可以利用（保存进位时的信息）；</li>
</ul>
</li>
<li><strong>目标：</strong>
<ul>
<li>懂得如何利用已知的十以内的加减法的结果，进行多位的加减法运算；</li>
<li>计算时需要从后向前计算；</li>
<li>需要保留进位的信息；</li>
<li>确保计算结果一定是准确的；</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>这应该是一个强化学习的过程——只有计算正确时，才会获得奖励。其中，尝试探索的动作空间是：</p>
<ul>
<li>如何利用十以内的加减</li>
<li>通过怎样的计算顺序</li>
<li>如何利用额外的存储</li>
</ul>
</li>
<li>
<p>最终以此来生成一个完整的加法运算流程。</p>
</li>
</ul>
<hr>
<h3 id="使用-rl-训练-agent">使用 RL 训练 Agent</h3>
<hr>
<p>Agent 的 While 循环模式恰好符合 Bellman 方程的形式。</p>
<hr>
<blockquote>
<p>通过强化学习训练 Agent，直观上，状态空间和奖励都不难定义，难的是究竟如何定义 Action 空间。</p>
</blockquote>
<hr>
<ul>
<li>例如十以内的加减法为什么可以成为加法的 Action？</li>
<li>进一步，当我们尝试训练乘法时，九九乘法表一定在我们的 Action 空间中，那如何凭空让机器找到这个“九九乘法表”呢？</li>
<li>甚至计算乘法时，加法也需要在 Action 空间中。这意味着，强化学习能学会内容是有序的，而且 Action 空间的生成也是依赖之前的训练结果的。</li>
<li>这个结果并不意外，《技术的本质》一书中就提到过人类技术的发展是渐进的，而不是突变的。</li>
</ul>
<hr>
<blockquote>
<p>牛顿无法简单的通过阅读代数和几何来发明微积分。问题是，要生成全新的想法，还缺什么？</p>
</blockquote>
<p><strong>有可能达成 AGI 的新范式应当需要 Agent + LLM 的联合训练，而不是各自的单独训练。</strong></p>
<hr>
<h2 id="thanks">Thanks!</h2>
]]></content:encoded>
    </item>
    
    <item>
      <title>大语言模型原理分享</title>
      <link>https://blog.uglyboy.cn/slides/1.-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%88%86%E4%BA%AB/</link>
      <pubDate>Tue, 21 Nov 2023 01:45:37 +0800</pubDate>
      
      <guid>https://blog.uglyboy.cn/slides/1.-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86%E5%88%86%E4%BA%AB/</guid>
      <description>大语言模型原理分享 什么是大语言模型？ 当我说了很多话之后，我马上要说 $\Box$ 数学公式描述 $w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是： $$ p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i}) $$ 大语言模型</description>
      <content:encoded><![CDATA[<h1 id="大语言模型br原理分享">大语言模型<!-- raw HTML omitted -->原理分享</h1>
<hr>
<h2 id="什么是大语言模型">什么是大语言模型？</h2>
<hr>
<p>当我说了很多话之后，我马上要说 $\Box$</p>
<hr>
<h2 id="数学公式描述">数学公式描述</h2>
<hr>
<p>$w_1, w_2,\dots, w_{N}$ 是一个单词序列，这个序列的概率分布是：</p>
<p>$$
p(w_{1},w_{2},\dots,w_{N})=\prod^N_{i=1}p(w_{i}|w_{1},w_{2},\dots,w_{i})
$$</p>
<hr>
<h2 id="大语言模型能做什么">大语言模型能做什么？</h2>
<hr>
<ul>
<li>大模型能记住它看到过的一切信息。</li>
<li>大模型对于已经看到过的信息，有一定的泛化能力（有限度的推广）。</li>
</ul>
<hr>
<h3 id="大模型能达到怎样的泛化能力">大模型能达到怎样的泛化能力？</h3>
<blockquote>
<p>大模型可以涌现出智能吗？</p>
</blockquote>
<hr>
<h2 id="大语言模型不能做什么">大语言模型不能做什么？</h2>
<hr>
<ol>
<li>大模型无法判别一个 $\{[0|1]^*\}$ 序列中是否有奇数个 $1$。</li>
<li>给定 $n$ 大模型无法生成 $(aa)^n$。</li>
<li>大模型无法判定 $\{0^n\#1^n\}$ 形式的序列。</li>
<li>大模型无法执行加法运算。</li>
<li>$\dots$</li>
</ol>
<hr>
<p>大语言模型没有，也不可能具有推理能力。</p>
<blockquote>
<p>大语言模型只是记住了足够多的别人的推理，然后用类比的方法将这些推理泛化了而已。</p>
</blockquote>
<hr>
<h2 id="大语言模型是如何将信息泛化的">大语言模型是如何将信息泛化的？</h2>
<hr>
<ul>
<li>通过相似度计算来进行泛化，然后通过概率分布来进行选择。
<ol>
<li>粗略的可以如下理解：可以用同义词替代的都能被泛化。</li>
<li>这种泛化的替代能力是可以保留相对位置信息的（例如一道数学题中的数字变了，它可以泛化到后续的解题过程中，都用新数字替代原来的数字）。</li>
<li>在训练样本充分的情况下，可以跨语言进行同义词泛化。</li>
</ol>
</li>
</ul>
<hr>
<h1 id="q--a">Q &amp; A</h1>
]]></content:encoded>
    </item>
    
    <item>
      <title>共情理论</title>
      <link>https://blog.uglyboy.cn/slides/%E5%85%B1%E6%83%85%E7%90%86%E8%AE%BA/</link>
      <pubDate>Tue, 20 Nov 2018 08:03:50 +0800</pubDate>
      
      <guid>https://blog.uglyboy.cn/slides/%E5%85%B1%E6%83%85%E7%90%86%E8%AE%BA/</guid>
      <description>传统经济学未能描述的人类行为方式</description>
      <content:encoded><![CDATA[<h1 id="共情理论">共情理论</h1>
<blockquote>
<p>传统经济学未能描述的人类行为方式</p>
</blockquote>
<hr>
<h3 id="女生找男生修电脑应不应该很快修好">女生找男生修电脑，应不应该很快修好？</h3>
<hr>
<blockquote>
<p>面对问题，直男们的第一反应就是寻找解决方案并将问题解决，这本来是很合逻辑的事情。</p>
<p>但女生找你诉苦，并不是去问你应该怎么办的，不是为了找你寻求解决方案，其实是想得到你的支持与共情。</p>
</blockquote>
<h2 id="知乎经常被女生说成是直男该怎么办">——知乎《经常被女生说成是直男，该怎么办？》</h2>
<!-- raw HTML omitted -->
<h3 id="功利动机">功利动机</h3>
<h3 id="共情动机">共情动机</h3>
<!-- raw HTML omitted -->
<ul>
<li>指为了达成某一目的，而产生的获取明确指向性信息的行为。
<ul>
<li>衣食住行</li>
<li>解决刚需的购物行为</li>
<li>搜索、咨询、知识付费</li>
</ul>
</li>
</ul>
<ul>
<li>指没有明确目的，但为了获得情感链接与情感体验，打发无聊，而产生的获取信息的行为。
<ul>
<li>与朋友闲聊</li>
<li>刷知乎、B站、抖音、猜你喜欢</li>
<li>看综艺、电视剧</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
<p><strong>断言：未来的营销市场，会和过去一样，赢得共情的玩家赢得功利市场</strong></p>
<hr>
<h3 id="两种动机的不同解法">两种动机的不同解法</h3>
<h4 id="功利动机-1"><code>功利动机</code></h4>
<ul>
<li>解决用户的明确需求，帮助用户快速达成目标或获取目标信息；</li>
</ul>
<h4 id="共情动机-1"><code>共情动机</code></h4>
<ul>
<li>源源不断地提供可以与用户共情的信息；</li>
<li>用户在获取信息前是不知道信息能否与自己共情的，所以用户需要的是可评判的信息源；</li>
</ul>
<hr>
<h3 id="你会选择从哪里获取信息">你会选择从哪里获取信息？</h3>
<ul>
<li>对信息源的评判标准，最重要的是：
<ul>
<li>人设（信息的共情程度）；</li>
<li>信息的频率；</li>
<li>新信息；</li>
</ul>
</li>
<li>一个人通常有多个信息源</li>
<li>人会因为信息源<em>共情能力</em>的变化，调整从之获取信息的频率；</li>
</ul>
<hr>
<h3 id="信息的三要素">信息的三要素</h3>
<ul>
<li>信息的编码 (Coding)</li>
<li>信息的内容 (Message)</li>
<li>信息的观点 (Key Point)</li>
</ul>
<blockquote>
<p>三者都可以形成共情，没有高下之分。相比之下，编码和内容通常贡献更多的共情点。</p>
</blockquote>
<hr>
<h4 id="如何改变一个人的观点">如何改变一个人的观点？</h4>
<hr>
<ul>
<li>人与一条信息发生共情时，就会倾向于接受这个信息的观点
<ul>
<li>《奇葩说》征服你的是观点吗？是逻辑吗？是一段感人的音乐和一个你感同身受的故事（信息的编码和内容共情）；</li>
<li>骗子的套路都是与你共情，然后就会形成信任；</li>
</ul>
</li>
<li>宗教传销的要义皆尽于此。</li>
</ul>
<hr>
<h3 id="测试一下你对共情的理解">测试一下你对共情的理解</h3>
<hr>
<h6 id="解决问题优先判断共情动机是否在起主要作用">解决问题优先判断共情动机是否在起主要作用</h6>
<hr>
<h4 id="奢侈品品牌应当如何营销">奢侈品品牌应当如何营销？</h4>
<ul>
<li>奢侈品的品牌，自然是主要解决用户的共情需求的；
<ul>
<li>人设</li>
<li>频率</li>
<li>上新</li>
</ul>
</li>
</ul>
<hr>
<h6 id="提升信息的共情程度">提升信息的共情程度</h6>
<hr>
<h4 id="有什么办法可以进一步提升爱情婚姻的质量">有什么办法可以进一步提升爱情（婚姻）的质量？</h4>
<ul>
<li>人设和频率基本上是固定的，所以只能通过信息内容来提升共情程度；
<ul>
<li>编码</li>
<li>内容</li>
<li>观点</li>
</ul>
</li>
</ul>
<hr>
<h6 id="说服一个人靠的不是逻辑而是共情">说服一个人，靠的不是逻辑，而是共情</h6>
<hr>
<h4 id="当你在给孩子讲道理时孩子却在搞怪怎么办">当你在给孩子讲道理时，孩子却在搞怪，怎么办？</h4>
<ul>
<li>“从前有个孩子不听话，后来他死了……”——《麦兜的故事》</li>
<li>小红书是如何卖奢侈品包包的</li>
</ul>
<blockquote>
<p>这个包很贵！但我的男朋友很爱我买给了我；你的男朋友爱你吗？你也值得拥有这个包包！</p>
</blockquote>
<hr>
<h6 id="理解共情动机对功利动机的影响">理解共情动机对功利动机的影响</h6>
<hr>
<h4 id="见投资人或客户时究竟要讲什么故事才有效">见投资人或客户时，究竟要讲什么故事才有效？</h4>
<hr>
<h6 id="共情理论在商业中的复杂应用">共情理论在商业中的复杂应用</h6>
<hr>
<h4 id="私域营销应该怎么做看哪些指标">私域营销应该怎么做？看哪些指标？</h4>
<hr>
<h2 id="几个共情的案例">几个共情的案例</h2>
<hr>
<h6 id="共情案例之编码共情">共情案例之编码共情</h6>
<hr>
<h4 id="编码共情的价值">编码共情的价值</h4>
<ul>
<li>一个人在异国他乡，遇到一个懂得他母语的人，他一定会特别愿意与这个人聊天，哪怕仅仅是编码共情；</li>
<li>拼多多、蜜雪冰城的传播曲都是改编自耳熟能详的音乐旋律，通过音乐的编码共情，让用户更容易接受信息内容；</li>
<li>如果一个人说的一个梗恰好你知道，两个人会相视一笑，显著提升共情体验；</li>
</ul>
<hr>
<h6 id="对于信息源而言新也是尤为重要的一个要素">对于信息源而言，新也是尤为重要的一个要素</h6>
<hr>
<h4 id="保持新鲜感也是共情的重要因素">保持新鲜感也是共情的重要因素</h4>
<ul>
<li>用户需要的是新的共情的信息，而不仅仅是共情的信息：
<ul>
<li>老梗重复次数多了，就不共情的；</li>
<li>如果只是共情，翻资料查档案馆就可以了；但大家都选择去看最新的节目。</li>
</ul>
</li>
<li>新的信息，重要的是体验和感受，而不是信息究竟有多新；
<ul>
<li>下拉刷新、知乎日报就能给人“新”的感受；</li>
<li>你平时跟人沟通时是不是时常能带来新的话题呢？你的父辈们呢？</li>
</ul>
</li>
</ul>
<hr>
<h6 id="共情案例之友情">共情案例之友情</h6>
<hr>
<h4 id="友情是什么">友情是什么？</h4>
<ul>
<li>“朋友”是某个信息源：
<ul>
<li>“朋友”往往常见于同学、同事这类拥有共同经历的人，因为彼此在信息的编码和内容上有明显的共情点；</li>
<li>朋友间信息交流的频率降低，友情自然就淡掉了（回忆一下人人网如何帮我们重拾友情）；</li>
<li>聊得来的朋友，会更频繁的聊天；</li>
</ul>
</li>
</ul>
<hr>
<h6 id="共情的网络效应">共情的网络效应</h6>
<hr>
<h4 id="共情的网络效应-1">共情的网络效应</h4>
<ul>
<li>共情具有群体性；
<ul>
<li>具有共同共情点的人们，彼此之间都会形成共情，从而形成群体。</li>
</ul>
</li>
<li>群体中会自发出现地位稳固的<strong>意见领袖</strong>；
<ul>
<li>群体中总会有更容易与他人形成社交关系的人；</li>
<li>群体共情会从网状结构变成星状结构；</li>
</ul>
</li>
</ul>
<hr>
<h6 id="共情案例之这些都是共情">共情案例之这些都是共情</h6>
<hr>
<h4 id="这些都是共情在起作用">这些都是共情在起作用</h4>
<ul>
<li>塑造品牌就是在打造一个共情编码。换句话说，品牌是共情，不要用功利动机的视角来理解它；</li>
<li>爽文、流行电视剧、热门梗（脱口秀）都是可以与更多人共情的信息；他们部分找到了构建共情信息的方法论；</li>
</ul>
<hr>
<h6 id="共情案例之这些都是共情-1">共情案例之这些都是共情</h6>
<hr>
<h4 id="这些都是共情在起作用-1">这些都是共情在起作用</h4>
<ul>
<li>直播间的主播、短视频的up主、微博大V、公众号等等都是共情体系下的 KOL。他们擅长的是成为很多人的优质信息提供者。不要忘记KOL也需要粉丝的帮助；</li>
<li>当一个APP追求用户时长时，它就进入了共情的大市场竞争中。高效的功利解决方案带不来用户时长。（一个找对象的APP，究竟是否应该快速找到对象？）</li>
</ul>
<hr>
<h6 id="共情案例之提升共情的小技巧">共情案例之提升共情的小技巧</h6>
<hr>
<h4 id="这些都可以帮我们更好的共情">这些都可以帮我们更好的共情</h4>
<ul>
<li>买杂志或者看热门电视剧，我们总是要看最新的。因为最新的才能带来更好的共情体验。
<ul>
<li>这也是为什么共情解决方案的APP都是下拉刷新（你又有XX条新消息）；</li>
<li>ZARA、SheIn、喜茶、瑞幸的成功都离不开上新；</li>
</ul>
</li>
</ul>
<hr>
<h6 id="共情案例之提升共情的小技巧-1">共情案例之提升共情的小技巧</h6>
<hr>
<h4 id="这些都可以帮我们更好的共情-1">这些都可以帮我们更好的共情</h4>
<ul>
<li>认识新朋友时，我们总会问对方哪里人，以便快速寻找到共情的内容，形成共情；</li>
<li>如果你不确定是否能创造与对方共情的信息，可以尝试重复或认同对方的信息来提升共情，因为对方自己与自己总是能共情的。
<ul>
<li>这一点对应的现象：社交媒体的交互都有点赞，但没有踩。</li>
</ul>
</li>
</ul>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
